<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>J. Lyle Kim | JUNHYUNG LYLE KIM</title>
    <link>https://jlylekim.github.io/author/j.-lyle-kim/</link>
      <atom:link href="https://jlylekim.github.io/author/j.-lyle-kim/index.xml" rel="self" type="application/rss+xml" />
    <description>J. Lyle Kim</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Copyright 2025 Junhyung Lyle Kim</copyright><lastBuildDate>Wed, 24 Jul 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://jlylekim.github.io/images/icon_hu6a253511a905c4c58ef48adc8d74e746_25674_512x512_fill_lanczos_center_2.png</url>
      <title>J. Lyle Kim</title>
      <link>https://jlylekim.github.io/author/j.-lyle-kim/</link>
    </image>
    
    <item>
      <title>A Catalyst Framework for the Quantum Linear System Problem via the Proximal Point Algorithm</title>
      <link>https://jlylekim.github.io/blog/qlsp-ppa/</link>
      <pubDate>Wed, 24 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://jlylekim.github.io/blog/qlsp-ppa/</guid>
      <description>&lt;!-- This blog post is about my recent work on distributed quantum state tomography using local stochastic factored gradient descent,[^kim2023local] published in [Control System Letters, IEEE 2023](https://ieeexplore.ieee.org/document/9810003). This is a joint work with my advisors [Prof. Tasos Kyrillidis](https://akyrillidis.github.io/about/) and [Prof. Cesar A. Uribe](https://cauribe.rice.edu/), and my good friend [Taha Toghani](https://sites.google.com/view/mttoghani). --&gt;
&lt;p&gt;This blog post is about my recent work on solving quantum linear system problem with (classical) proximal point method. This post is written with my advisor &lt;a href=&#34;https://akyrillidis.github.io/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Tasos Kyrillidis&lt;/a&gt;, and can also be found &lt;a href=&#34;https://akyrillidis.github.io/explore-quantum/QLSP_PPA.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. This is a joint work with &lt;a href=&#34;https://akyrillidis.github.io/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Tasos Kyrillidis&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/view/naihuichia/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Nai-Hui Chia&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Solving systems of linear equations is essential in numerous applications, from scientific computing to machine learning. Classical algorithms like Gaussian elimination and iterative methods scale poorly with the problem size, often rendering large-scale problems intractable. Quantum algorithms offer a potential breakthrough by reducing the dependence on the problem dimensions from polynomial to logarithmic, as demonstrated by the Harrow-Hassidim-Lloyd (HHL) algorithm. Nevertheless, the performance of quantum algorithms is severely impacted by the condition number $\kappa$ of the input matrix, which measures the sensitivity of the system to numerical errors. High-condition numbers can significantly degrade the efficiency of quantum solutions, a challenge we address in this study.&lt;/p&gt;
&lt;p&gt;Our approach leverages the classical proximal point algorithm (PPA), a method known for improving the conditioning of the problem in optimization tasks. By adapting the PPA to the quantum linear system problem (QLSP), we introduce a framework that enhances the performance of existing quantum linear system solvers. The key innovation lies in modifying the matrix to be inverted, thus reducing the effective condition number and improving convergence rates. This method can be seamlessly integrated with existing quantum solvers, providing a versatile tool for tackling a broader class of linear system problems.&lt;/p&gt;
&lt;h2 id=&#34;the-quantum-linear-system-problem-qlsp&#34;&gt;The Quantum Linear System Problem (QLSP)&lt;/h2&gt;
&lt;p&gt;The Quantum Linear System Problem (QLSP) aims to prepare a quantum state proportional to the solution vector $x^\star$ of a linear system $Ax=b$. This task is central to many quantum algorithms, including those for solving differential equations, machine learning, and optimization problems. Existing quantum algorithms, such as the HHL algorithm, achieve significant speedups over classical methods by reducing the complexity from polynomial to logarithmic in the problem dimension $N$. However, their performance is often limited by the condition number $\kappa$ of the matrix $A$.&lt;/p&gt;
&lt;p&gt;The condition number $\kappa$ is defined as the ratio of the largest to the smallest singular value of $A$. High-condition numbers indicate ill-conditioned systems that are susceptible to numerical errors, which can significantly slow down convergence and affect the final accuracy. Addressing this limitation is crucial for extending the applicability of quantum algorithms to real-world problems, which often involve ill-conditioned matrices.&lt;/p&gt;
&lt;p&gt;A proper definition of the QLSP problem is as follows:






  



  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/qlsp-ppa/def_hu415ed2a3b76a4b45357dd8f7776c07e5_426873_2000x2000_fit_q90_lanczos.jpg&#34; &gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/qlsp-ppa/def_hu415ed2a3b76a4b45357dd8f7776c07e5_426873_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;714&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Our proposed framework leverages the proximal point algorithm (PPA) to address this challenge. By iteratively refining the solution through a modified matrix inversion process, our approach effectively preconditions the system, reducing the impact of high-condition numbers. This approach not only improves convergence rates but also broadens the range of problems that quantum algorithms can efficiently solve.&lt;/p&gt;
&lt;h2 id=&#34;our-contributions&#34;&gt;Our Contributions&lt;/h2&gt;
&lt;p&gt;We present a novel meta-algorithmic framework that enhances the performance of existing quantum linear system solvers. Our contributions are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Improved Condition Number:&lt;/strong&gt; Our method reduces the effective condition number from $\kappa$ to $\frac{\kappa(1+\eta)}{\kappa + \eta}$, where $\eta$ is a tunable parameter. This reduction alleviates the dependence of the algorithm on the condition number, leading to faster convergence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Flexibility:&lt;/strong&gt; The proposed framework is versatile, allowing different QLSP solvers to be used as subroutines. This flexibility enables users to choose the most appropriate solver for their specific problem.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tunable Parameter $\eta$:&lt;/strong&gt; By carefully selecting the parameter $\eta$, users can balance the trade-off between runtime and approximation error, optimizing overall algorithmic complexity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our approach stands out by directly approximating the solution vector $x^\star = A^{-1} b$ through iterative refinement. This is in contrast to existing methods that focus on approximating the inverse of the coefficient matrix $A$. By inverting a (normalized) modified matrix $I + \eta A$, our algorithm effectively preconditions the system, resulting in a better-conditioned problem that converges more rapidly.&lt;/p&gt;
&lt;h2 id=&#34;algorithmic-and-theoretical-intuition&#34;&gt;Algorithmic and Theoretical Intuition&lt;/h2&gt;
&lt;p&gt;Our proposed algorithm employs the proximal point algorithm (PPA) to solve the QLSP. The core idea is to invert the (normalized) modified matrix $I + \eta A$ instead of the original matrix $A$, thus improving the system&amp;rsquo;s conditioning. The algorithm proceeds as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Initialization:&lt;/strong&gt; Start with an initial guess $x_0 + \eta b$ for the solution vector.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Matrix Modification:&lt;/strong&gt; Modify the matrix $A$ to $\frac{I + \eta A}{|| I + \eta A ||}$.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Refinement:&lt;/strong&gt; Apply any existing QLSP solver to invert the modified matrix and apply to the initial guess.&lt;/li&gt;
&lt;/ul&gt;






  



  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/qlsp-ppa/algo_hu415ed2a3b76a4b45357dd8f7776c07e5_424320_2000x2000_fit_q90_lanczos.jpg&#34; &gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/qlsp-ppa/algo_hu415ed2a3b76a4b45357dd8f7776c07e5_424320_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;726&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;The convergence rate and error bounds of our algorithm are rigorously analyzed. By carefully choosing the parameter $\eta$, the algorithm balances the trade-off between runtime and approximation error. Our theoretical analysis demonstrates that the proposed method achieves faster convergence and greater accuracy than existing quantum solvers, especially for ill-conditioned problems.&lt;/p&gt;
&lt;p&gt;We also provide a detailed complexity analysis, showing that our method significantly reduces the dependence on the condition number $\kappa$. Please check our paper for the complete and detailed theoretical analysis.&lt;/p&gt;
&lt;h2 id=&#34;empirical-observations-over-theory&#34;&gt;Empirical observations over theory&lt;/h2&gt;






  



  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/qlsp-ppa/query-scale_hu415ed2a3b76a4b45357dd8f7776c07e5_356304_2000x2000_fit_q90_lanczos.jpg&#34; &gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/qlsp-ppa/query-scale_hu415ed2a3b76a4b45357dd8f7776c07e5_356304_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1464&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;In Figure 1, we show how the query complexity scales as a function of the condition number $\kappa$. The orangle line is the state-of-the-art QLSP solver based on the discrete adiabatic theorem. Simply by “wrapping” the original QLSP solver with our proposed method, the query complexity to achieve a fixed accuracy improves as $\kappa$ increases.&lt;/p&gt;






  



  
  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/qlsp-ppa/numerical_hu415ed2a3b76a4b45357dd8f7776c07e5_613796_2000x2000_fit_q90_lanczos.jpg&#34; &gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/qlsp-ppa/numerical_hu415ed2a3b76a4b45357dd8f7776c07e5_613796_2000x2000_fit_q90_lanczos.jpg&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;1454&#34;&gt;
&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;In Figure 2, we show, based on our theoretical analysis, the breakdown of the “improvement” and the “overhead” for two different QLSP solvers as subroutines.&lt;/p&gt;
&lt;h2 id=&#34;conclusions-and-future-work&#34;&gt;Conclusions and Future Work&lt;/h2&gt;
&lt;p&gt;Our proposed framework significantly alleviates the dependence on the condition number in solving the Quantum Linear System Problem (QLSP). By leveraging the proximal point algorithm (PPA), we introduce a meta-algorithm that enhances the performance of existing quantum solvers, broadening their applicability to more challenging, ill-conditioned problems.&lt;/p&gt;
&lt;p&gt;Future work will explore several promising directions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-step PPA Implementation:&lt;/strong&gt; Extending the algorithm to multi-step PPA implementations could further improve convergence rates and reduce runtime. This involves developing efficient methods for handling multiple iterations of the modified matrix inversion.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Warm Starting:&lt;/strong&gt; Investigating strategies for better initialization (warm starting) can lead to improved convergence. This may involve using prior knowledge about the solution or leveraging other quantum or classical solvers to provide a good starting point.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hybrid Approaches:&lt;/strong&gt; Combining our framework with other optimization techniques, such as quantum-inspired algorithms, could yield even more efficient solvers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our work opens new avenues for research in quantum computing and optimization, providing a robust foundation for developing more advanced algorithms that can tackle a wider range of problems.&lt;/p&gt;
&lt;!-- [^zeng2019]: J. Zeng, K. Ma, and Y. Yao. &#34;On global linear convergence in stochastic nonconvex optimization for semidefinite programming.&#34; IEEE Transactions on Signal Processing 67.16. 4261-4275. 2019,

[^bhojanapalli2016]: S. Bhojanapalli, A. Kyrillidis, S. Sanghavi. Dropping Convexity for Faster Semi-definite Optimization. 29th Annual Conference on Learning Theory, in Proceedings of Machine Learning Research. 49:530-582. 2016.

[^lan2020]: Guanghui Lan, Soomin Lee, and Yi Zhou. Communication-efficient algorithms for decentralized and stochastic optimization. Mathematical Programming 180.1-2. 237-284. 2020.

[^kim2023local]: J. L. Kim, M. T. Toghani, C. A. Uribe and A. Kyrillidis. Local Stochastic Factored Gradient Descent for Distributed Quantum State Tomography. IEEE Control Systems Letters, vol. 7, pp. 199-204, 2023. --&gt;
</description>
    </item>
    
    <item>
      <title>Local Stochastic Factored Gradient Descent for Distributed Quantum State Tomography</title>
      <link>https://jlylekim.github.io/blog/local-sfgd/</link>
      <pubDate>Wed, 22 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://jlylekim.github.io/blog/local-sfgd/</guid>
      <description>&lt;p&gt;This blog post is about my recent work on distributed quantum state tomography using local stochastic factored gradient descent,&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; published in &lt;a href=&#34;https://ieeexplore.ieee.org/document/9810003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Control System Letters, IEEE 2023&lt;/a&gt;. This is a joint work with my advisors &lt;a href=&#34;https://akyrillidis.github.io/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Tasos Kyrillidis&lt;/a&gt; and &lt;a href=&#34;https://cauribe.rice.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Cesar A. Uribe&lt;/a&gt;, and my good friend &lt;a href=&#34;https://sites.google.com/view/mttoghani&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Taha Toghani&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Quantum state tomography (QST) is one of the main procedures to identify the nature of imperfections in quantum processing unit (QPU) implementation. For more detailed background on QST, please refer to my &lt;a href=&#34;https://jlylekim.github.io/blog/acc-qst/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Given the previous blogpost, we will jump directly to the objective function. We again use low-rankness as our prior.
That is, we consider the reconstruction of a low-rank density matrix $\rho^\star \in \mathbb{C}^{d \times d}$ on a $n$-qubit Hilbert space, where $d=2^n$, through the following $\ell_2$-norm reconstruction objective:
\begin{align}
\label{eq:objective} \tag{1}
\min_{\rho \in \mathbb{C}^{d \times d}}
\quad &amp;amp; f(\rho) := \tfrac{1}{2} ||\mathcal{A}(\rho) - y||_2^2 \\&lt;br&gt;
\text{subject to}
\quad&amp;amp; \rho \succeq 0, ~\texttt{rank}(\rho) \leq r.
\end{align}&lt;/p&gt;
&lt;p&gt;Here, $y \in \mathbb{R}^m$ is the measured data through quantum computer or simulation, and $\mathcal{A}(\cdot): \mathbb{C}^{d \times d} \rightarrow \mathbb{R}^m$ is the linear sensing map. The sensing map relates the density matrix $\rho$ to the measurements through &lt;a href=&#34;https://en.wikipedia.org/wiki/Born_rule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Born rule&lt;/a&gt;: $\left( \mathcal{A}(\rho) \right)_i = \text{Tr}(A_i \rho),$ where $A_i \in \mathbb{C}^{d \times d},~i=1, \dots, m$ are the sensing matrices.&lt;/p&gt;
&lt;p&gt;One of the motivation for using the low-rank prior is that the sample complexity can be reduced to $O(r \cdot d \cdot \text{poly} \log d)$ from $O(d^2)$.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; However, low-rank constraint is a non-convex constraint, which is tricky to handle. To solve \eqref{eq:objective} as is using iterative methods like gradient descent, one needs to perform &lt;a href=&#34;https://en.wikipedia.org/wiki/Singular_value_decomposition&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;singular value decomposition&lt;/a&gt; on every iteration (in order to project onto the low-rank and PSD subspace), which is prohibitively expensive when $d$ is large, which is almost always the case as $d = 2^n$.&lt;/p&gt;
&lt;p&gt;To address that, instead of solving \eqref{eq:objective}, we proposed to solve a factorized version of it, following recent work &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;:
\begin{align}
\label{eq:factored-obj} \tag{2}
\min_{U \in \mathbb{C}^{d \times r}} f(UU^\dagger) := \tfrac{1}{2} || \mathcal{A} (UU^\dagger) - y ||_2^2,
\end{align}
where $U^\dagger$ denotes the &lt;a href=&#34;https://en.wikipedia.org/wiki/Conjugate_transpose&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;adjoint&lt;/a&gt; of $U$. Now, \eqref{eq:factored-obj} is an unconstrained problem, and we can use gradient descent on $U$, which iterates as follows:&lt;/p&gt;
&lt;!-- \begin{align}
\label{eq:fgd} \tag{4}
U_{k+1} &amp;= U_{k} - \eta \nabla f(U_k U_k^\dagger) \cdot U_k \\\\
&amp;= U_{k} - \eta \mathcal{A}^\dagger \left(\mathcal{A}(U_k U_k^\dagger) - y\right) \cdot U_k.
\end{align} --&gt;
&lt;p&gt;\begin{align*} \label{eq:fgd} \tag{3}
U_{i+1} &amp;amp;= U_{i} - \eta \nabla F(U_k U_k^\dagger) \cdot U_k \\&lt;br&gt;
&amp;amp;= U_k - \eta \left( \frac{1}{m} \sum_{i=1}^m ( \text{Tr}(A_k U_k U_t^\dagger) - y_k ) A_k \right) \cdot U_k
\end{align*}&lt;/p&gt;
&lt;!-- Here, $\mathcal{A}^\dagger: \mathbb{R}^m \rightarrow \mathbb{C}^{d \times d}$ is the adjoint of $\mathcal{A}$, defined as $\mathcal{A}^\dagger = \sum_{i=1}^m x_k A_k.$ $\eta$ is a hyperparameter called step size or learning rate. This method is called &#34;$\texttt{F}$actored $\texttt{G}$radient $\texttt{D}$escent&#34; ($\texttt{FGD}$), and was utilized to solve the non-convex objective function in Eq. \eqref{eq:factored-obj}, (surprisingly) with provable gaurantees.[^kyrillidis2018provable] --&gt;
&lt;p&gt;Even though \eqref{eq:factored-obj} is unconstrained and thus we can avoid performing the expensive singular value decomposition on every iteration, $m$ in \eqref{eq:fgd} is still extremely large. In particular, with $r=100$ and $n=30$, the reduced sample complexity still reaches $O\left(r \cdot d \cdot \text{poly}(\log d)\right) \approx 9.65 \times 10^{14}$.&lt;/p&gt;
&lt;h2 id=&#34;distributed-objective&#34;&gt;Distributed objective&lt;/h2&gt;
&lt;p&gt;To handle such explosion of data, We consider the setting where the measurements $y \in \mathbb{R}^m$ and the sensing matrices $\mathcal{A}: \mathbb{C}^{d\times d} \rightarrow \mathbb{R}^m$ from a central quantum computer are locally stored across $M$ different classical machines. These classical machines perform some local operations based on their local data, and communicate back and forth with the central quantum server. Mathematically, we can write the distributed objective as:
\begin{align} \label{eq:dist-obj} \tag{4}
\min_{U \in \mathbb{C}^{d \times r}}  g(U) &amp;amp;= \frac{1}{M} \sum_{i=1}^M g_i(U),    \\&lt;br&gt;
\text{where} \quad g_i(U) &amp;amp;:= \mathbb{E}_{j \sim \mathcal{D}_i} ||\mathcal{A}_i^j (UU^\dagger) - y_i^j ||_2^2.
\end{align}&lt;/p&gt;
&lt;p&gt;We illustrate the above objective with the figure bellow:






  



  
  











&lt;figure id=&#34;figure-illustration-of-distributed-quantum-state-tomography&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/local-sfgd/featured_hu13f4fe2809d1952c4d0168f1c8b27fcc_43292_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Illustration of distributed quantum state tomography.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/local-sfgd/featured_hu13f4fe2809d1952c4d0168f1c8b27fcc_43292_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;40%&#34; height=&#34;783&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Illustration of distributed quantum state tomography.
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;That is, $i$-th machine has sensing matrices $\mathcal{A}_i: \mathbb{C}^{d\times d} \rightarrow \mathbb{R}^{m_i}$ and measurement data $y_i \in \mathbb{R}^{m_i}$, such that the collection of $\mathcal{A}_i$ and $y_i$ for $i \in [M]$ recover the original $\mathcal{A}$ and $y$.&lt;/p&gt;
&lt;!-- $\cup_{i=1}^M \mathcal{A}_i = \mathcal{A}$  --&gt;
&lt;!-- and $\sum_{i=1}^M m_i = m$. --&gt;
&lt;h2 id=&#34;distributed-algorithm&#34;&gt;Distributed algorithm&lt;/h2&gt;
&lt;p&gt;A naive way to implement a distributed algorithm to solve \eqref{eq:dist-obj} is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each machine can take a (stochastic) gradient step:
\begin{align}
U_k^i = U_{k-1}^i - \eta_{t-1} \nabla g_i^{j_{t-1}} (U_{t-1}^i)
\end{align}&lt;/li&gt;
&lt;li&gt;Central quantum server receives next iterate for all $i$ and take average:
\begin{align}
U_k^i = U_{k-1}^i - \eta_{t-1} \nabla g_i^{j_{t-1}} (U_{t-1}^i)
\end{align}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, such intra-node communication is much more &amp;mdash;typically 3-4 order of magnitude more&amp;mdash; expensive than inter-node computation.&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; Therefore, it&amp;rsquo;s desirable to communicate as little as possible. One way to do so is by performing &lt;em&gt;local iterations&lt;/em&gt; on each machine, and communicate only once in a while. We propose the &lt;em&gt;Local Stochastic Factored Gradient Descent (Local SFGD)&lt;/em&gt; in the below pseudocode:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-pseudocode-for-local-stochastic-factored-gradient-descent-local-sfgd&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/local-sfgd/local-sfgd-algo_huf8b139424932042b8d09ec38c7b11bf5_121569_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Pseudocode for Local Stochastic Factored Gradient Descent (Local SFGD).&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/local-sfgd/local-sfgd-algo_huf8b139424932042b8d09ec38c7b11bf5_121569_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;721&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Pseudocode for Local Stochastic Factored Gradient Descent (Local SFGD).
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The initialization scheme in line 1 (or Eq. (7)) is an adaptation of &lt;a href=&#34;http://proceedings.mlr.press/v49/bhojanapalli16.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Theorem 11&lt;/a&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; to the distributed setting, and is crucial in theory to prove global convergence (however, in practice, we observe thant random intialization also works well).
Also notice that there are some pre-defined synchronization (or communication) steps $t_p$, for some $p \in \mathbb{N}$. The algorithm proceeds by, at each time step $t$, a stochastic FGD step is taken in parallel for each machine. Only if the time step equals a pre-defined synchronization step, the local iterates are sent to the server and their average is computed. The average is fed back to each machine, and the process repeats until the time step reaches user-input $T$.&lt;/p&gt;
&lt;h2 id=&#34;theoretical-guarantees&#34;&gt;Theoretical guarantees&lt;/h2&gt;
&lt;p&gt;We will not get into the details of the theoretical guarantees of Local SFGD in this post. Please refer to the &lt;a href=&#34;https://ieeexplore.ieee.org/document/9810003&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt; for more detailed discussion.&lt;/p&gt;
&lt;p&gt;That being said, we first introduce the assumptions on the function class and on the stochastic gradients:






  



  
  











&lt;figure id=&#34;figure-assumptions-1-and-2&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/local-sfgd/assumptions_huc479e5c8281c624f0ee0e7f6477675cc_122304_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Assumptions 1 and 2&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/local-sfgd/assumptions_huc479e5c8281c624f0ee0e7f6477675cc_122304_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;660&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Assumptions 1 and 2
  &lt;/figcaption&gt;


&lt;/figure&gt;

Assumption 1 is the standard strong-convexity and $L$-smoothness assumptions, &lt;em&gt;but are restricted (i.e., weaker) in the sense that they only need to hold for PSD matrices&lt;/em&gt;. Assumption 2 is quite standard on stochastic-optimization literature.&lt;/p&gt;
&lt;p&gt;Based on the above assumptions, we prove two results: local linear convergence with a constant step-size (Theorem 2), and local sub-linear conveergence with diminishing step-sizes (Theorem 4). Here, &amp;ldquo;local convergence&amp;rdquo; means that the convergence depends on the initialization.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-local-linear-convergence-with-a-constant-step-size&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/local-sfgd/theorem2_hu1a553baa570e41a187df39ec77da9c45_114691_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Local linear convergence with a constant step size&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/local-sfgd/theorem2_hu1a553baa570e41a187df39ec77da9c45_114691_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;552&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Local linear convergence with a constant step size
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Some remarks to make:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the last variance term, $\frac{\sigma^2}{M \alpha}$, also shows up in the convergence analysis of SFGD is reduced by the number
of machines $M$;&lt;/li&gt;
&lt;li&gt;we assume a single-batch is used in the proof; by using batch size $b &amp;gt; 1$, this term can be further divided by $b$;&lt;/li&gt;
&lt;li&gt;by plugging in $h = 1$ (i.e., synchronization happens on every iteration), the first variance term disappears, exhibiting similar local linear convergence to SFGD.&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;






  



  
  











&lt;figure id=&#34;figure-local-sublinear-convergence-with-diminishing-step-sizes&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/local-sfgd/theorem4_hu922ae10404d6c5eb49ce5f3736872bf2_109670_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Local sublinear convergence with diminishing step sizes&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/local-sfgd/theorem4_hu922ae10404d6c5eb49ce5f3736872bf2_109670_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;485&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Local sublinear convergence with diminishing step sizes
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;The main message of Theorem 4 is that, by using appropriately diminishing step-sizes, we can achieve local convergence (without any variance term), at the cost of slowing down the convergence rate to a sub-linear one.&lt;/p&gt;
&lt;h2 id=&#34;numerical-simulations&#34;&gt;Numerical simulations&lt;/h2&gt;
&lt;p&gt;We use the Local SFGD to reconstruct the Greenberger-Horne-Zeilinger (GHZ) state, using simulated measurement data from Qiskit.
GHZ state is known as maximally entangled quantum state, meaning that it exhibits the maximal inter-particle correlation, which does not exist in the classical mechanics. We are interested in: $(i)$ how the number of local steps affect the accuracy defined as
$ \varepsilon = || \hat{U}_t \hat{U}_t^\top - \rho^\star ||_F^2,$ where $\rho^\star = U^\star U^{\star \dagger}$ is the true density matrix for the GHZ state; and $(ii)$ the scalability of the distributed setup for various number of classical machines $M$.&lt;/p&gt;
&lt;!-- $\varepsilon = || \hat{U}_t \hat{U}_t^\top - \rho^\star_{\text{ghz}} ||_F^2$,  --&gt;






  



  
  











&lt;figure id=&#34;figure-local-sublinear-convergence-with-diminishing-step-sizes&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/local-sfgd/fig-crop_hu5d50ed01706b8c68eeead270a385b151_215634_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Local sublinear convergence with diminishing step sizes&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/local-sfgd/fig-crop_hu5d50ed01706b8c68eeead270a385b151_215634_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;1336&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Local sublinear convergence with diminishing step sizes
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;In the top panel of the above plot, we first fix the number of machines $M = 10$ and the number of total synchronization steps to be $100$, and vary the number of local iterations between two synchronization steps, i.e., $h \in {1, 10, 25, 50, 100, 200}.$ We use constant step size $\eta=1$ for all $h$.&lt;/p&gt;
&lt;p&gt;Increasing $h$, i.e., each distributed machine performing more local iterations, leads to faster convergence in terms of the synchronization steps.
Notably, the speed up gets marginal: e.g., there is not much difference between $h=100$ and $h=200$, indicating there is an ``optimal&#39;&#39; $h$ that leads to the biggest reduction in the number of synchronization steps. Finally, note that $\varepsilon$ does not decrease below certain level due to the inherent finite sampling error of quantum measurements.&lt;/p&gt;
&lt;p&gt;In the bottom panel, we plot the number of synchronization steps to reach $\varepsilon \leq 0.05,$ while fixing
% the number of local iterations, i.e., $h=20$. We vary the number of workers $M \in {5, 10, 15, 20}$, where each machine gets $200$ measurements. There is a significant speed up from $M=5$ to $M=15$, while for $M=20,$ it took one more syncrhonization step compared to $M=15,$ which is likely due to the stochasticity of SFGD within each machine.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. L. Kim, M. T. Toghani, C. A. Uribe and A. Kyrillidis. Local Stochastic Factored Gradient Descent for Distributed Quantum State Tomography. IEEE Control Systems Letters, vol. 7, pp. 199-204, 2023. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Gross, Y.-K. Liu, S. Flammia, S. Becker, and J. Eisert. Quantum state tomography via compressed
sensing. Physical review letters, 105(15):150401, 2010. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Kyrillidis, A. Kalev, D. Park, S. Bhojanapalli, C. Caramanis, and S. Sanghavi. Provable quantum state tomography via non-convex methods. npj Quantum Information, 4(36), 2018. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Guanghui Lan, Soomin Lee, and Yi Zhou. Communication-efficient algorithms for decentralized and stochastic optimization. Mathematical Programming 180.1-2. 237-284. 2020. &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;S. Bhojanapalli, A. Kyrillidis, S. Sanghavi. Dropping Convexity for Faster Semi-definite Optimization. 29th Annual Conference on Learning Theory, in Proceedings of Machine Learning Research. 49:530-582. 2016. &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Zeng, K. Ma, and Y. Yao. &amp;ldquo;On global linear convergence in stochastic nonconvex optimization for semidefinite programming.&amp;rdquo; IEEE Transactions on Signal Processing 67.16. 4261-4275. 2019, &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Convergence and Stability of the Stochastic Proximal Point Algorithm with Momentum</title>
      <link>https://jlylekim.github.io/blog/sppam/</link>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://jlylekim.github.io/blog/sppam/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;In this blog post, I will introduce the stochastic proximal point algorithm with momentum (SPPAM) based on &lt;a href=&#34;https://arxiv.org/abs/2111.06171&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this paper&lt;/a&gt;,&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; which is forthcoming in &lt;a href=&#34;https://l4dc.stanford.edu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Learning for Dynamics and Control (L4DC) 2022&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;
&lt;p&gt;We focus on unconstrained empirical risk minimization:
\begin{align}
\label{eq:obj} \tag{1}
\min_{x \in \mathbb{R}^p} ~f(x) = \frac{1}{n} \sum_{i=1}^n f_i(x).
\end{align}&lt;/p&gt;
&lt;p&gt;Stochastic gradient descent (SGD) has become the de facto method to solve \eqref{eq:obj} used by the machine learning community, mainly due to its computational efficiency. SGD iterates as follows:
\begin{align}
\label{eq:sgd} \tag{2}
x_{t+1} = x_t  - \eta \nabla f_{i_t}(x_t),
\end{align}
where $\eta$ is the step size, and $\nabla f_i$ is the (stochastic) gradient computed at the $i$-th data point.&lt;/p&gt;
&lt;!-- #### Properties of SGD and Its Momentum Extension. --&gt;
&lt;p&gt;While computationally efficient, SGD in \eqref{eq:sgd} suffers from two major limitations: $(i)$ slow convergence, and $(ii)$ numerical instability.
Due to the (stochastic) gradient noise, SGD could take longer to converge in terms of iterations.
Moreover, SGD suffers from numerical instabilities both in theory and practice, allowing only a small range of $\eta$ values that lead to convergence, which often depend on unknown quantities. &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&#34;acceleration-via-momentum&#34;&gt;Acceleration via Momentum.&lt;/h3&gt;
&lt;p&gt;With respect to the slow convergence, many variants of accelerated methods have been proposed, including the Polyak&amp;rsquo;s momentum &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; and the Nesterov&amp;rsquo;s acceleration &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; methods.
These methods allow faster (sometimes optimal) convergence rates, while having virtually the same computational cost as SGD.
In particular, SGD with momentum (SGDM) iterates as follows:
\begin{align}
\label{eq:sgdm} \tag{3}
x_{t+1} = x_t  - \eta \nabla f_{i_t}(x_t) + \beta (x_t - x_{t-1}),
\end{align}
where $\beta \in [0,1)$ is the momentum parameter.
The intuition is that, if the direction from $x_{t-1}$ to $x_t$ was &amp;ldquo;correct,&amp;rdquo; then SGDM utilizes this inertia weighted by the momentum parameter $\beta,$ instead of just relying on the current point $x_t.$&lt;/p&gt;
&lt;!-- Much of the state-of-the-art performance has been achieved with SGDM \citep{huang2017densely, howard2017mobilenets, he2016deep}. --&gt;
&lt;p&gt;Yet, SGDM could be hard to tune: SGDM adds another hyperparameter&amp;mdash;momentum $\beta$&amp;mdash;to an already sensitive stochastic procedure of SGD.
As such, various works have found that such motions could aggravate the instability of SGD. &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;  &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;!-- For instance, \cite{liu_accelerating_2019} and \cite{kidambi_insufficiency_2018} show that accelerated SGD does not in general provide any acceleration over SGD, regardless of careful tuning; further, accelerated SGD may diverge for the step sizes that SGD converges.  --&gt;
&lt;!-- \cite{assran_convergence_2020} also show that, even with finite-sum of quadratic functions, accelerated SGD may diverge under the usual choices of step size and momentum. --&gt;
&lt;!-- See also \cite{loizou2020momentum, devolder2014first, d2008smooth} for more discussions on this topic. --&gt;
&lt;h3 id=&#34;stability-via-proximal-updates&#34;&gt;Stability via Proximal Updates.&lt;/h3&gt;
&lt;p&gt;With respect to the numerical stability, variants of SGD that utilize proximal updates have recently been proposed.
The proximal point algorithm (PPA) obtains the next iterate for minimizing $f$ by solving the following optimization problem:
\begin{align}
\label{eq:ppa} \tag{6}
x_{t+1} = \arg \min_{x\in \mathbb{R}^p} \left\{ f(x) + \tfrac{1}{2\eta} || x - x_t ||_2^2 \right\},
\end{align}
which is equivalent to implicit gradient descent (IGD) by the first-order optimality condition:
\begin{align}
\label{eq:igd} \tag{7}
x_{t+1} = x_t - \eta \nabla f(x_{t+1}).
\end{align}
In words, instead of minimizing $f$ directly, PPA minimizes $f$ with an additional quadratic term.
This small change brings a major advantage to PPA: if $f$ is convex, the added quadratic term can make the problem strongly convex; if $f$ is non-convex, PPA can make it convex.&lt;/p&gt;
&lt;!-- \citep{ahn_proximal_2020}. --&gt;
&lt;p&gt;Thanks to this conditioning property, PPA exhibits different behavior compared to GD in the deterministic setting.
For a convex function $f$, PPA satisfies: &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;
\begin{align}
\label{eq:ppm-conv-rate-guller} \tag{8}
f(x_T) - f(x^\star) \leq O \left( \tfrac{1}{\sum_{t=1}^T \eta_t} \right),&lt;br&gt;
\end{align}
after $T$ iterations.
By setting the step size $\eta_t$ to be large, PPA can converge ``arbitrarily&#39;&#39; fast.&lt;/p&gt;
&lt;p&gt;Due to this remarkable property, PPA was soon considered in the stochastic setting, dubbed as stochastic proximal iterations (SPI) &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt; or implicit SGD &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;.
These works generally indicate that, in the asymptotic regime, SGD and SPI/ISGD have the same convergence behavior; but in the non-asymptotic regime, SPI/ISGD outperforms SGD due to numerical stability provided by utilizing proximal updates.&lt;/p&gt;
&lt;!-- In the stochastic setting, \cite{toulis_proximal_2021} show that
SPPA enjoys an exponential discount of the initial condition, regardless of the step size $\eta$ and the smoothness parameter $L$. 
On the contrary, for SGD, 
both $\eta$ and $L$ show up within an exponential term, amplifying the initial conditions, leading to even divergence if misspecified \citep{moulines_non-asymptotic_2011}. --&gt;
&lt;!-- In particular, \cite{toulis_proximal_2021} introduced stochastic errors in proximal point algorithms (SPPA) and analyzed its convergence and stability, which iterates similar to: 
\begin{align}
    x_{t+1} &amp;= x_t - \eta \left( \nabla f(x_{t+1}) + \varepsilon_{t+1} \right)   \label{eq:stoc-ppa}. \tag{4}
\end{align}
Without stochastic errors, \eqref{eq:stoc-ppa} is known as the proximal point algorithm (PPA) \citep{rockafellar_monotone_1976, guler_convergence_1991} or the implicit gradient descent (IGD).  --&gt;
&lt;!-- PPA/IGD is known to converge with minimal assumptions on hyperparameter tuning, by improving the conditioning of the optimization problem; more details in Section~\ref{sec:prelim}. --&gt;
&lt;h3 id=&#34;our-approach-stochastic-ppa-with-momentum-sppam&#34;&gt;Our Approach: Stochastic PPA with Momentum (SPPAM).&lt;/h3&gt;
&lt;p&gt;The main question we wanted to answer in this work was as follows:
$$\text{Can we accelerate stochastic PPA while preserving its numerical stability?}$$&lt;/p&gt;
&lt;!-- To address both issues, we introduce stochastic PPA with momentum (SPPAM), and study its convergence and stability b...ehavior. SPPAM directly incorporates the momentum term akin to \eqref{eq:sgdm} into \eqref{eq:stoc-ppa}:  --&gt;
&lt;p&gt;SPPAM iterates as follows:
\begin{align}
x_{t+1} &amp;amp;= x_t - \eta \left (\nabla f(x_{t+1}) + \varepsilon_{t+1}\right) + \beta (x_t - x_{t-1})  \label{eq:acc-stoc-ppa}. \tag{5}
\end{align}&lt;/p&gt;
&lt;!-- \paragraph{Our Focus and Contributions.} --&gt;
&lt;!-- #### Our Focus and Contributions. --&gt;
&lt;!-- Stochastic accelerated variants of PPA have received limited attention: how momentum interacts with the stability that PPA provides remains unstudied. 
To the best of our knowledge, \textit{no momentum has been considered for stochastic proximal point updates that, beyond convergence, also studies the stability of the acceleration motions.}
This is the aim of this work. 
Our contributions are summarized as:
- We introduce stochastic PPA with momentum (SPPAM), and study its convergence and stability behavior. SPPAM directly incorporates the momentum term akin to \eqref{eq:sgdm} into \eqref{eq:stoc-ppa}: 
  \begin{align}
    x_{t+1} &amp;= x_t - \eta \left (\nabla f(x_{t+1}) + \varepsilon_{t+1}\right) + \beta (x_t - x_{t-1})  \label{eq:acc-stoc-ppa}. \tag{5} 
  \end{align}
- We study whether adding momentum $\beta$ results in faster convergence akin to SGDM, while preserving the numerical stability, inherited by utilizing proximal updates akin to SPPA. 
- We show that SPPAM enjoys linear convergence to a neighborhood (Theorem \ref{thm:lin-conv}) with a better contraction factor than SPPA (Lemma \ref{lem:SPPAM-contraction}). We further characterize the conditions on $\eta$ and $\beta$ that result in acceleration (Corollay \ref{cor:acc-condition}). 
Finally, we characterize the condition that leads to the exponential discount of initial conditions for SPPAM (Theorem~\ref{thm:init-discount-condition}), which is significantly easier to satisfy compared to SGDM.
- Empirically, we confirm our theory with experiments on generalized linear models (GLM), including
linear and Poisson regressions with different condition numbers. 
As expected, SGD and SGDM converge only for specific choices of $\eta$ and $\beta$, while SPPA converges for a much wider range of $\eta.$ 
SPPAM enjoys the advantages of both acceleration from the momentum and stability from the proximal step: it converges for the range of $\eta$ that SPPA converges but with faster rate, which improves or matches that of SGDM, when the latter converges.
\end{itemize} --&gt;
&lt;!-- ## Preliminaries --&gt;
&lt;!-- #### Accelerated PPA
Accelerated PPA was first proposed in deterministic setting in \cite{guler_new_1992}, where Nesterov&#39;s acceleration was applied \emph{after} solving the proximal step in \eqref{eq:ppa}. This yields the convergence rate of the form: 
\begin{align}
    f(x_T) - f(x^\star) \leq O \left( \frac{1}{ \big( \sum_{t=1}^T \sqrt{\eta_t} \big)^2} \right), \label{eq:ppm-acc-conv-rate-guller} \tag{9}
\end{align}
which is faster than the rate in \eqref{eq:ppm-conv-rate-guller}. 
This bound is based on Nesterov&#39;s momentum schedules, but does not study the effect in stability different tuning pairs $(\eta, \beta)$ might have. 
Moreover, as can be seen in \eqref{eq:ppm-conv-rate-guller}, PPA can already achieve arbitrarily fast convergence, given it is implemented exactly.
Hence, following works focused on studying the conditions under which the proximal step in \eqref{eq:ppa} can be computed inexactly, while still exhibiting some acceleration \citep{lin_universal_2015, lin_catalyst_2018}; similar analyses were later extended to the stochastic setting in \cite{kulunchakov_generic_2019}.


\cite{chadha_accelerated_2021} and \cite{deng_minibatch_2021} also considered accelerated SPPA.
Both of these works apply a convoluted 2- or 3-step Nesterov&#39;s procedure after the proximal step, where $f_i$ was further approximated with auxiliary functions. 
Yet, stability arguments via proximal updates are less apparent due to the auxiliary functions, requiring specific step size and momentum schedules, which might involve an additional one-dimensional optimization per iteration; see also Theorem~\ref{thm:init-discount-condition}.
A summary of these algorithms is provided in the table below.







  



  
  











&lt;figure id=&#34;figure-summary-of-related-works&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/sppam/related-work_hu8fc69290f50e18d7a3ab267652c95375_201924_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Summary of related works&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/sppam/related-work_hu8fc69290f50e18d7a3ab267652c95375_201924_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;873&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Summary of related works
  &lt;/figcaption&gt;


&lt;/figure&gt;
 --&gt;
&lt;!-- #### Intuition of SPPAM in \eqref{eq:acc-stoc-ppa} --&gt;
&lt;!-- In contrast to the aforementioned works, we include Polyak&#39;s momentum \citep{polyak_methods_1964} directly to SPPA, yielding \eqref{eq:acc-stoc-ppa}.  --&gt;
&lt;p&gt;Apart from the similarity between SPPAM in \eqref{eq:acc-stoc-ppa} and SGDM in \eqref{eq:sgdm}, SPPAM shares the same geometric intuition as Polyak&amp;rsquo;s momentum for SGDM.
Disregarding the stochastic errors, the update in \eqref{eq:acc-stoc-ppa} follows from the solution of:
\begin{align*}
\arg \min_{x \in \mathbb{R}^p} \left\{ f(x) + \tfrac{1}{2\eta} ||x-x_t||_2^2 - \tfrac{\beta}{\eta} \langle x_t - x_{t-1}, x \rangle \right\}.
\end{align*}&lt;/p&gt;
&lt;p&gt;We can get a sense of the behavior of SPPAM from this expression.
First, for large $\eta$, the algorithm is minimizing the original $f.$
For small $\eta$, the algorithm not only tries to stay local by minimizing the quadratic term, but also tries to minimize
$-\frac{\beta}{\eta} \langle x_t - x_{t-1}, x \rangle$.
By the definition of inner product, this means that $x$, on top of minimizing $f$ and staying close to $x_t$, also tries to move along the direction from $x_{t-1}$ to $x_t$. This intuition aligns with that of Polyak&amp;rsquo;s momentum.&lt;/p&gt;
&lt;h2 id=&#34;the-quadratic-model-case&#34;&gt;The quadratic model case&lt;/h2&gt;
&lt;p&gt;For simplicity, we first consider the convex quadratic optimization problem under the deterministic setting.
Specifically, we consider the objective function:
\begin{align}
\label{eq:obj-quad} \tag{10}
f(x) = \frac{1}{2} x^\top A x - b^\top x,
\end{align}
where $A \in \mathbb{R}^{p\times p}$ is positive semi-definite with eigenvalues $\left[ \lambda_1, \dots, \lambda_p \right]$.
Under this scenario,
we can study how the step size $\eta$ and the momentum $\beta$ affect each other, by deriving exact conditions that lead to convergence for each algorithm.
The comparison list includes
gradient descent (GD), gradient descent with momentum (GDM), the PPA, and PPA with momentum (PPAM).&lt;/p&gt;
&lt;!-- Propositions~\ref{prop:gd} and \ref{prop:gdm} for GD and GDM are from {{\cite{goh2017why}}}, and included for completeness.  --&gt;
&lt;!-- Propositions 1 and 3 for GD and GDM are from {{\cite{goh2017why}}}, and included for completeness.
Proofs for PPA and PPAM in Propositions 2 and 4 can be found in the extended version of this work \citep{kim2021convergence}. --&gt;
&lt;p&gt;&lt;strong&gt;Proposition 1 (GD)&lt;/strong&gt;&lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;
&lt;em&gt;To minimize \eqref{eq:obj-quad} with gradient descent, the step size $\eta$ needs to satisfy $0 &amp;lt; \eta &amp;lt; \frac{2}{\lambda_i}~~\forall i$, where $\lambda_i$ is the $i$-th eigenvalue of $A$&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 2 (PPA)&lt;/strong&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
&lt;em&gt;To minimize \eqref{eq:obj-quad} with PPA, the step size $\eta$ needs to satisfy&lt;/em&gt; $\left| \frac{1}{1+\eta \lambda_i} \right| &amp;lt; 1~~\forall i$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 3 (GDM)&lt;/strong&gt;&lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;
&lt;em&gt;To minimize \eqref{eq:obj-quad} with gradient descent with momentum, the step size $\eta$ needs to satisfy $0 &amp;lt; \eta \lambda_i &amp;lt; 2 + 2\beta$ ~ $\forall i$, where $0 \leq \beta &amp;lt; 1.$&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Proposition 4 (PPAM)&lt;/strong&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;
&lt;em&gt;Let $\delta_i = \left( \frac{\beta+1}{1+\eta \lambda_i} \right)^2 - \frac{4\beta}{1+\eta \lambda_i}.$
To minimize \eqref{eq:obj-quad} with PPAM, the step size $\eta$ and momentum $\beta$ need to satisfy $~\forall i$:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\eta &amp;gt; \frac{\beta-1}{\lambda_i},\quad$ if $\delta_i \leq 0$;&lt;/li&gt;
&lt;li&gt;$\frac{\beta+1}{1+\eta \lambda_i} + \sqrt{\delta_i} &amp;lt; 2,\quad$ if $\delta_i &amp;gt; 0$ and $\frac{\beta+1}{1+\eta \lambda_i} \geq 0$;&lt;/li&gt;
&lt;li&gt;$\frac{\beta+1}{1+\eta \lambda_i} - \sqrt{\delta_i} &amp;gt; -2,\quad$ otherwise.&lt;/li&gt;
&lt;/ul&gt;






  



  
  











&lt;figure id=&#34;figure-we-generate-a-in-mathbbrptimes-p-and-b-xstar-inmathbbrp-from-mathcaln0-i-where-p100-and-the-condition-number-of-a-is-10-we-sweep-eta-and-beta-from--5-to-5-with-02-interval-we-plot-the-accuracy-x_t---xstar_22-after-100-iterations-with-the-maximum-replaced-by-10&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/sppam/quadratic-model_hu7ea8cb333b3b20abe999ce52ffba51b9_61870_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;We generate $A \in \mathbb{R}^{p\times p}$ and $b, x^\star \in\mathbb{R}^p$ from $\mathcal{N}(0, I)$, where $p=100$ and the condition number of $A$ is 10. We sweep $\eta$ and $\beta$ from $-5$ to $5$, with $0.2$ interval. We plot the accuracy $||x_t - x^\star||_2^2$ after 100 iterations, with the maximum replaced by 10.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/sppam/quadratic-model_hu7ea8cb333b3b20abe999ce52ffba51b9_61870_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;239&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    We generate $A \in \mathbb{R}^{p\times p}$ and $b, x^\star \in\mathbb{R}^p$ from $\mathcal{N}(0, I)$, where $p=100$ and the condition number of $A$ is 10. We sweep $\eta$ and $\beta$ from $-5$ to $5$, with $0.2$ interval. We plot the accuracy $||x_t - x^\star||_2^2$ after 100 iterations, with the maximum replaced by 10.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Given the above propositions, we can study the stability with respect to the step size $\eta$ and the momentum $\beta$ for the considered algorithms.
Numerical simulations support the above propositions, and are illustrated in the above figure, matching the theoretical conditions exhibited above.&lt;/p&gt;
&lt;p&gt;In particular, for GD, only a small range of step sizes $\eta$ leads to convergence (small white band); this &amp;ldquo;white band&amp;rdquo; corresponds to the restriction that $\eta$ has to satisfy $\eta &amp;lt; \tfrac{2}{\lambda_i}$ for all $i$.
On the other hand, PPA/IGD converges in much wider choices of $\eta$; this is apparent from Proposition 2, since $\left| \frac{1}{1+\eta \lambda_i} \right|$ can be arbitrarily small for larger values of $\eta$.
GDM requires both $\eta$ and $\beta$ to be in a small region to converge, following Proposition 3.
Finally, PPAM converges in much wider choices of $\eta$ and $\beta$; e.g., the conditions in Proposition 4 define different regions of the pair $(\eta, \beta)$ that lead to convergence, some of which set both $\eta$ and $\beta$ to be negative.
Note that the empirical convergence region of PPAM almost exactly matches the theoretical region that leads to convergence in Proposition 4.&lt;/p&gt;
&lt;p&gt;In the next section, we will see how this pattern translates to a general strongly convex function $f,$ with stochasticity.&lt;/p&gt;
&lt;!-- In the remainder of the paper, we study how such pattern translates to a general strongly convex function $f,$ with stochasticity. --&gt;
&lt;h2 id=&#34;main-results&#34;&gt;Main Results&lt;/h2&gt;
&lt;p&gt;In this section, we theoretically characterize the convergence and stability behavior of SPPAM.&lt;/p&gt;
&lt;p&gt;We follow the stochastic errors of PPA, as set up in &lt;a href=&#34;https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssb.12405&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this paper&lt;/a&gt;.&lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;
We can then express \eqref{eq:acc-stoc-ppa} as:
\begin{align*}
x_{t+1}^+ &amp;amp;= x_t - \eta \nabla f(x_{t+1}^+) + \beta (x_t - x_{t-1})  \\&lt;br&gt;
x_{t+1} &amp;amp;= x_{t+1}^+ - \eta  \varepsilon_{t+1}.
\end{align*}&lt;/p&gt;
&lt;p&gt;Note that $x_{t+1}^+$ is an auxiliary intermediate variable that is used for the analysis only.&lt;/p&gt;
&lt;p&gt;We further assume the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assumption 1&lt;/strong&gt; &lt;em&gt;$f$ is a $\mu$-strongly convex function: for some fixed $\mu &amp;gt; 0$ and for all $x$ and $y$,&lt;/em&gt;
\begin{align*}
\langle \nabla f(x)-\nabla f(y), x - y \rangle \geq \mu ||x-y ||_2^2.
\end{align*}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assumption 2&lt;/strong&gt; &lt;em&gt;There exists fixed $\sigma^2 &amp;gt; 0$ such that, given the natural filtration $\mathcal{F}_{t-1},$&lt;/em&gt;
\begin{align*}
\mathbb{E}\left[ \varepsilon_t \mid \mathcal{F}_{t-1} \right] = 0 \quad\text{and}\quad
\mathbb{E}\left[ | \varepsilon_t \mid \mathcal{F}_{t-1} |^2 \right] \leq \sigma^2
\quad\text{for all}\quad t.
\end{align*}&lt;/p&gt;
&lt;h3 id=&#34;is-sppam-faster-than-sppa&#34;&gt;Is SPPAM faster than SPPA?&lt;/h3&gt;
&lt;p&gt;We first study whether SPPAM enjoys faster convergence than SPPA. We start with the iteration invariant bound, which expresses the expected error at $x_{t+1}$ in terms of its previous iterates:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem 5&lt;/strong&gt;
&lt;em&gt;For $\mu$-strongly convex $f(\cdot)$, SPPAM satisfies the following iteration invariant bound&lt;/em&gt;:
\begin{align} \label{eq:onestep-acc-stoc-prox} \tag{11}
\mathbb{E} \big[ || x_{t+1 }- x^\star ||_2^2 \big] &amp;amp;\leq \tfrac{4}{(1+\eta \mu)^2} \mathbb{E} \big[ ||x_t - x^\star ||_2^2 \big] \\&lt;br&gt;
&amp;amp;\quad+ \tfrac{4\beta^2}{(1+\eta \mu)^2\left( 4-(1+\beta)^2 \right)} \mathbb{E} \big[ ||x_{t-1} - x^\star ||_2^2 \big] + \eta^2 \sigma^2.
\end{align}&lt;/p&gt;
&lt;p&gt;Notice that all terms &amp;ndash;except the last one&amp;ndash; are divided by $(1+\eta \mu)^2.$
Thus, large step sizes $\eta$ help convergence (to a neighborhood), reminiscent of the convergence behavior of PPA in \eqref{eq:ppm-conv-rate-guller}.&lt;/p&gt;
&lt;p&gt;Based on \eqref{eq:onestep-acc-stoc-prox},
we can write the following $2\times 2$ system that characterizes the progress of SPPAM:
\begin{align}
\label{eq:two-by-two-onestep} \tag{12}
\begin{bmatrix}
\mathbb{E} \big[ ||x_{t+1} - x^\star ||_2^2 \big] \\&lt;br&gt;
\mathbb{E} \big[ ||x_t - x^\star ||_2^2 \big]
\end{bmatrix} &amp;amp;\leq
A
\cdot
\begin{bmatrix}
\mathbb{E} \big[ ||x_t - x^\star ||_2^2 \big] \\&lt;br&gt;
\mathbb{E} \big[ ||x_{t-1} - x^\star ||_2^2 \big]
\end{bmatrix}
+
\begin{bmatrix}
\eta^2 \sigma^2 \\&lt;br&gt;
0
\end{bmatrix},
\end{align}&lt;/p&gt;
&lt;p&gt;where $A =
\begin{bmatrix}
\frac{4}{(1+\eta \mu)^2} &amp;amp; \frac{4\beta^2}{(1+\eta \mu)^2\left( 4-(1+\beta)^2 \right)} \\&lt;br&gt;
1 &amp;amp; 0
\end{bmatrix}$.
It is clear that the spectrum of the contraction matrix $A$ determines the convergence rate to a neighborhood.
This is summarized in the following lemma:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lemma 6&lt;/strong&gt;
&lt;em&gt;The maximum eigenvalue of $A$, which determines the convergence rate of SPPAM, is&lt;/em&gt;:
\begin{align} \label{eq:acc-stoc-ppa-conv-rate} \tag{13}
\tfrac{2}{(1+\eta \mu)^2} + \sqrt{ \tfrac{4}{(1+\eta \mu)^4} + \tfrac{4\beta^2}{(1+\eta \mu)^2(4 - (1+\beta)^2)}}.
\end{align}&lt;/p&gt;
&lt;p&gt;Notice the one-step contraction factor in \eqref{eq:acc-stoc-ppa-conv-rate} is of order $O(1/\eta^2),$ exhibiting acceleration compared to that of SPPA for strongly convex objectives: $1/(1+2\eta \mu) \approx O(1/\eta).$&lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;However, due to the additional terms, it is not immediately obvious when SPPAM enjoys faster convergence than SPPA. We thus characterize this condition more precisely in the following corollary:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Corollary 7&lt;/strong&gt;
&lt;em&gt;For $\mu$-strongly convex $f$, SPPAM enjoys better contraction factor than SPPA if&lt;/em&gt;:
\begin{align*}
\frac{4\beta^2}{4 - (1+\beta)^2} &amp;lt;  \frac{\eta^2 \mu^2 - 6\eta\mu - 3}{(1+\eta \mu)^2}.
\end{align*}&lt;/p&gt;
&lt;p&gt;In words, for a fixed step size $\eta$ and given a strongly convex parameter $\mu$, there is a range of momentum parameters $\beta$ that exhibits acceleration compared to SPPA.&lt;/p&gt;
&lt;p&gt;In contrast to (stochastic) gradient method analyses in convex optimization, where acceleration is usually shown by improving the dependency on the condition number from $\kappa = \tfrac{L}{\mu}$ to $\sqrt{\kappa},$ such a claim can hardly be made for stochastic proximal point methods. This is also the case in deterministic setting, where (Nesterov&amp;rsquo;s) accelerated PPA converges for strongly convex $f$ as in:&lt;sup id=&#34;fnref:15&#34;&gt;&lt;a href=&#34;#fn:15&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;15&lt;/a&gt;&lt;/sup&gt;
\begin{align}
f(x_T) - f(x^\star) \leq O \left( \frac{1}{ \big( \sum_{t=1}^T \sqrt{\eta_t} \big)^2} \right), \label{eq:ppm-acc-conv-rate-guller} \tag{14}
\end{align}
which is faster than the rate in \eqref{eq:ppm-conv-rate-guller}.&lt;/p&gt;
&lt;!-- see \eqref{eq:ppm-conv-rate-guller} and \eqref{eq:ppm-acc-conv-rate-guller}.  --&gt;
&lt;p&gt;As shown in Theorem 5, our convergence analysis of SPPAM does not depend on $L$-smoothness at all. This robustness of SPPAM is also confirmed in numerical simulations in the next section, where SPPAM exhibits the fastest convergence rate, virtually independent of the different settings considered.&lt;/p&gt;
&lt;!-- We now formalize the convergence behavior of SPPAM.
In particular, we characterize the condition that leads to an exponential discount of the initial conditions.
By unrolling the recursion of SPPAM in \eqref{eq:two-by-two-onestep} for $T$ iterations, we obtain:  --&gt;
&lt;h3 id=&#34;is-sppam-more-stable-than-sgdm&#34;&gt;Is SPPAM more stable than SGDM?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Theorem 9&lt;/strong&gt;
&lt;em&gt;For $\mu$-strongly convex $f$, assume SPPAM is initialized with&lt;/em&gt; $x_0 = x_{-1}$. Then, after $T$ iterations, we have:
\begin{align}  \label{eq:Tstep-acc-stoc-prox} \tag{15}
&amp;amp;\mathbb{E} \big[ ||x_T - x^\star ||_2^2 \big]
\leq  \frac{2 \sigma_1^T}{\sigma_1 - \sigma_2}
%
\left(  \left( ||x_0-x^\star ||_2^2 + \tfrac{\eta^2 \sigma^2}{1-\theta}\right) \cdot (1+\theta) \right)&lt;br&gt;
+
\frac{\eta^2 \sigma^2}{1-\theta},
\end{align}
where
$\theta=\frac{4}{(1+\eta\mu)^2} + \tfrac{4\beta^2}{(1+\eta\mu)^2(4-(1+\beta)^2)}.$&lt;/p&gt;
&lt;p&gt;Here, $\sigma_{1, 2}$ are the eigenvalues of $A$, and
\begin{align} \label{eq:discount-init} \tag{16}
\tfrac{2 \sigma_1^T}{\sigma_1 - \sigma_2}  =  \tau^{-1}
\cdot
\left( \tfrac{2}{(1+\eta\mu)^2} + \tau \right)^T
\quad \text{with} \quad
\tau = \sqrt{ \tfrac{4}{(1+\eta \mu)^4} + \tfrac{4\beta^2}{(1+\eta \mu)^2(4 - (1+\beta)^2)}}.
\end{align}&lt;/p&gt;
&lt;p&gt;The above theorem states that the term in \eqref{eq:discount-init} determines the discounting rate of the initial conditions.
In particular, the condition that leads to an exponential discount
of the initial conditions
is characterized by the following theorem:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem 10&lt;/strong&gt;
&lt;em&gt;Let the following condition hold&lt;/em&gt;:
\begin{align} \label{eq:init-discount-condition} \tag{17}
% \left( \frac{1-\beta}{1+2 \eta \mu} \right)^2 + \frac{\beta^2}{1+2\eta \mu} \left( \frac{2-\beta}{2-\beta(1+\beta)} \right) &amp;lt; \frac{1}{4}.
\tau = \sqrt{ \tfrac{4}{(1+\eta \mu)^4} + \tfrac{4\beta^2}{(1+\eta \mu)^2(4 - (1+\beta)^2)}} &amp;lt; \tfrac{1}{2}.
\end{align}
&lt;em&gt;Then, for $\mu$-strongly convex $f$, initial conditions of SPPAM exponentially discount: i.e., in \eqref{eq:Tstep-acc-stoc-prox}&lt;/em&gt;,&lt;br&gt;
\begin{align*}
\tfrac{2 \sigma_1^T}{\sigma_1 - \sigma_2}  =
\tau^{-1} \cdot   \left( \tfrac{2}{(1+\eta\mu)^2} + \tau \right)^T
=C^T, \quad\text{where}\quad C \in (0, 1).
\end{align*}&lt;/p&gt;
&lt;p&gt;To provide more context of the condition in &lt;strong&gt;Theorem 10&lt;/strong&gt;, we make an ``unfair&amp;quot; comparison of  \eqref{eq:init-discount-condition}, which holds for general strongly convex $f,$ to the condition that accelerated SGD requires for strongly convex &lt;em&gt;quadratic objective&lt;/em&gt; in \eqref{eq:obj-quad}.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://proceedings.mlr.press/v119/assran20a.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This paper&lt;/a&gt;
shows that Nesterov&amp;rsquo;s accelerated SGD converges to a neighborhood at a linear rate for strongly convex quadratic objective if
$\max{ \rho_\mu(\eta, \beta),~\rho_L(\eta, \beta) } &amp;lt; 1$,
where $\rho_\lambda(\eta, \beta)$ for $\lambda \in {\mu, L}$ is defined as:
\begin{align} \label{eq:sgdm-spectral-rad}
\rho_\lambda(\eta, \beta) =
\begin{cases}
\frac{|(1+\beta)(1-\eta \lambda)|}{2} + \frac{\sqrt{\Delta_\lambda}}{2} &amp;amp; \text{if}~\Delta_\lambda \geq 0, \&lt;br&gt;
\sqrt{\beta (1-\eta \lambda)} &amp;amp; \text{otherwise},
\end{cases}
\end{align}
with $\Delta_\lambda = (1+\beta)^2 (1-\eta \lambda)^2 - 4\beta(1-\eta \lambda)$.
This condition for convergence can thus be divided into three cases, depending on the range of $\eta \lambda$.
Define $\psi_{\beta, \eta, \lambda} = (1 + \beta)(1 - \eta \lambda)$. Then:
\begin{align*}
\begin{cases}
\eta \lambda \geq 1, &amp;amp;  \text{Converges if }-\psi_{\beta, \eta, \lambda} + \sqrt{\Delta_\lambda} &amp;lt; 2, \\
\frac{(1-\beta)^2}{(1+\beta)^2} \leq \eta \lambda &amp;lt; 1,
&amp;amp; \text{Always converges}, \\&lt;br&gt;
\eta \lambda &amp;lt; \frac{(1-\beta)^2}{(1+\beta)^2}, &amp;amp;\text{Converges if }\psi_{\beta, \eta, \lambda} + \sqrt{\Delta_\lambda}&amp;lt; 2 .
\end{cases}
\end{align*}&lt;/p&gt;
&lt;p&gt;Now, consider the standard momentum value $\beta = 0.9.$
For the first case, the convergence requirement translates to
$1 \leq \eta \lambda \leq \tfrac{24}{19}.$
The second range is given by $\frac{1}{361} \leq \eta \lambda &amp;lt; 1$.
The third condition is lower bounded by 2 for $\beta=0.9,$ leading to divergence.
Combining, accelerated SGD requires $0.0028 \approx \frac{1}{361} \leq \eta \lambda \leq \frac{24}{19} \approx 1.26$ to converge for strongly convex quadratic objectives, set aside that this bound has to satisfy for (unknown) $\mu$ or $L$.
Albeit an unfair comparison, for general strongly convex objective, \eqref{eq:init-discount-condition} becomes $\eta \mu &amp;gt; 4.81$ for $\beta=0.9.$
Even though $\mu$ is unknown, one can see this condition is easy to satisfy, by using a sufficiently large step size $\eta$.&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;In this section, we perform numerical experiments to study the convergence behaviors of SPPAM, SPPA, SGDM, and SGD, using generalized linear models (GLM).&lt;/p&gt;
&lt;!-- {\cite{nelder1972generalized}}.  --&gt;
&lt;!-- Let $b_i \in \mathbb{R}$ be the label, $a_i \in \mathbb{R}^{p}$ be the features, and $x^\star \in \mathbb{R}^p$ be the model parameter of interest. GLM assumes that $b_i$ follows an exponential family distribution: $b_i \mid a_i \sim \exp \left( \frac{\gamma b_i - c_1(\gamma)}{\omega} c_2(b_i, \omega)  \right).$ --&gt;
&lt;!-- Here, $\gamma=\langle a_i, x^\star \rangle$ is the linear predictor, $\omega$ is the dispersion parameter related to the variance of $b_i$, and $c_1(\cdot)$ and $c_2(\cdot)$ are known real-valued functions.  --&gt;
&lt;p&gt;GLM subsumes a wide family of models including linear, logistic, and Poisson regressions. Different models connects the linear predictor $\gamma=\langle a_i, x^\star \rangle$ through different \textit{mean} functions $h(\cdot)$.
We focus on linear and Poisson regression models, where mean functions are defined respectively as $h(\gamma) = \gamma$ and $h(\gamma) = e^\gamma$.
The former is an &amp;ldquo;easy&amp;rdquo; case, where objective is strongly convex, satisfying Assumption 1. The latter is a &amp;ldquo;hard&amp;rdquo; case with non-Lipschitz continuous gradients, where SGD and SGDM are expected to suffer.&lt;/p&gt;
&lt;!-- {\cite{toulis_statistical_2014}} introduced an efficient, exact implementation of SPPA for GLM. We adapt this procedure to SPPAM in \eqref{eq:acc-stoc-ppa}; see Algorithm~\ref{alg:sppam-glm}. Its derivation can be found in \cite{kim2021convergence}. --&gt;






  



  
  











&lt;figure id=&#34;figure-top-linear-regression-with-condition-number-kappa-in-1-5-10-with-gaussian-noise-level-texttt1e-3-bottom-poisson-regression-with-condition-number-kappa-in-1-3-5-we-set-p--n--100-in-both-cases-batch-size-is-10-for-all-algorithms-the-median-number-of-iterations-to-reach-varepsilon--001-is-plotted-shaded-area-are-the-standard-deviations-across-5-experiments&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/sppam/normal-poisson_hubb8b80653c08a11bdd0af6bf6f9df321_313409_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;TOP: Linear regression with condition number $\kappa \in {1, 5, 10}$ with gaussian noise level $\texttt{1e-3}.$ BOTTOM: Poisson regression with condition number $\kappa \in {1, 3, 5}$. We set $p = n = 100$ in both cases. Batch size is 10 for all algorithms. The median number of iterations to reach $\varepsilon = 0.01$ is plotted. Shaded area are the standard deviations across 5 experiments.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/sppam/normal-poisson_hubb8b80653c08a11bdd0af6bf6f9df321_313409_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;698&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    TOP: Linear regression with condition number $\kappa \in {1, 5, 10}$ with gaussian noise level $\texttt{1e-3}.$ BOTTOM: Poisson regression with condition number $\kappa \in {1, 3, 5}$. We set $p = n = 100$ in both cases. Batch size is 10 for all algorithms. The median number of iterations to reach $\varepsilon = 0.01$ is plotted. Shaded area are the standard deviations across 5 experiments.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;!-- We generate the data as follows. $A \in \mathbb{R}^{p \times n}$ and $x^\star \in \mathbb{R}^p$ are drawn from $\mathcal{N}(0, I).$ For the normal case, we generate $b_i = \langle a_i, x^\star \rangle$, and for the Poisson case, we generate $b_i \sim \text{Poisson} (e^{\langle a_i, x^\star \rangle} )$ for $i = 1, \dots, n.$ 
For each experimental setup, we run SPPAM (blue), SPPA (orange), SGDM (green), and SGD (red) for $10^4$ iterations. 
We repeat each experiment for 5 independent trials, and 
plot the median number of iterations to reach precision $\varepsilon \leq 10^{-2},$ along with the standard deviation.
We measure the precision 
$\varepsilon = \frac{\|b - \hat{b}\|_2^2}{\|b\|_2^2},$ 
where $b$ is the true label and $\hat{b}$ is the predicted label. --&gt;
&lt;p&gt;In the top row of above figure, we present the results for the linear regression with different condition numbers, with gaussian noise level $\texttt{1e-3}$. We run each algorithm constant step size $\eta$ varying from $10^{-3}$ to $10^3$ with $10\times$ increment, and with $\beta=0.9$.
As expected, SGD and SGDM only converge for specific step size $\eta$, while SPPA and SPPAM converge for much wider ranges.
In terms of convergence rate, SPPAM converges faster than SPPA in all scenarios, which improves or matches the rate of SGDM, when it converges.
As $\kappa$ increases, the range of $\eta$ that leads to convergence for SGD and SGDM shrinks; notice the sharper &amp;ldquo;$\lor$&amp;rdquo; shape for SGD and SGDM for $\kappa = 10$ (3rd), compared to $\kappa=5$ (2nd) or $\kappa=1$ (1st).
SPPA also slightly slows down as $\kappa$ increases, while SPPAM converges essentially in the same manner for all scenarios.&lt;/p&gt;
&lt;p&gt;Such trend is much more pronounced for the Poisson regression case presented in the bottom row.
Due to the exponential mean function $h(\cdot)$ for Poisson model, the outcomes are extremely sensitive, and its likelihood does not satisfy standard assumptions like $L$-smoothness. As such, SGD and SGDM struggles with slow convergence even when $\kappa = 1$ (1st), while also exhibiting instability&amp;mdash;each method converges only for a single choice of $\eta$ considered.
Similar trend is shown when $\kappa=3$ (2nd) where SPPA starts slowing down.
For $\kappa = 5$ (3rd), all methods except for SPPAM did not make much progress in $10^4$ iterations, for the entire range of $\eta$ and $\beta$ considered. Quite remarkably, SPPAM still converges in the same manner without sacrificing both the convergence rate and the range of hyperparameters that lead to convergence.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We propose the stochastic proximal point algorithm with momentum (SPPAM), which directly incorporates Polyak&amp;rsquo;s momentum inside the proximal step. We show that SPPAM converges to a neighborhood at a faster rate than stochastic proximal point algorithm (SPPA), and characterize the conditions that result in acceleration. Further, we prove linear convergence of SPPAM to a neighborhood, and provide conditions that lead to an exponential discount of the initial conditions, akin to SPPA. We confirm our theory with numerical simulations on linear and Poisson regression models; SPPAM converges for all the step sizes that SPPA converges, with a faster rate that matches or improves SGDM.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Junhyung Lyle Kim, Panos Toulis, and Anastasios Kyrillidis. Convergence and stability of the
stochastic proximal point algorithm with momentum. arXiv preprint arXiv:2111.06171, 2021. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Eric Moulines and Francis R. Bach. Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Machine Learning. In J. Shawe-Taylor, R. S. Zemel, P. L. Bartlett, F. Pereira, and
K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 24, pages 451–459. Curran Associates, Inc., 2011. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Robert M Gower, Nicolas Loizou, Xun Qian, Alibek Sailanbayev, Egor Shulgin, and Peter
Richtarik. SGD: General Analysis and Improved Rates. Proceedings of the 36 th International
Conference on Machine Learning, page 10, 2019. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Boris T Polyak. Some methods of speeding up the convergence of iteration methods. Ussr computational mathematics and mathematical physics, 4(5):1–17, 1964. &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Yurii Nesterov et al. Lectures on convex optimization, volume 137. Springer, 2018. &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Chaoyue Liu and Mikhail Belkin. Accelerating sgd with momentum for over-parameterized learning. arXiv preprint arXiv:1810.13395, 2018. &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Rahul Kidambi, Praneeth Netrapalli, Prateek Jain, and Sham Kakade. On the insufficiency of existing momentum schemes for stochastic optimization. In 2018 Information Theory and Applications Workshop (ITA), pages 1–9. IEEE, 2018. &lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Mahmoud Assran and Michael Rabbat. On the Convergence of Nesterov’s Accelerated Gradient
Method in Stochastic Settings. Proceedings of the 37 th International Conference on Machine
Learning, 2020. &lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Osman Guler. On the convergence of the proximal point algorithm for convex minimization. ¨ SIAM
journal on control and optimization, 29(2):403–419, 1991. &lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ernest K Ryu and Stephen Boyd. Stochastic Proximal Iteration: A Non-Asymptotic Improvement
Upon Stochastic Gradient Descent. Author website, page 42, 2017. &lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Hilal Asi and John C Duchi. Stochastic (approximate) proximal point methods: Convergence,
optimality, and adaptivity. SIAM Journal on Optimization, 29(3):2257–2290, 2019. &lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Panos Toulis and Edoardo M Airoldi. Asymptotic and finite-sample properties of estimators based
on stochastic gradients. The Annals of Statistics, 45(4):1694–1727, 2017. &lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Panos Toulis, Thibaut Horel, and Edoardo M Airoldi. The proximal robbins–monro method. Journal
of the Royal Statistical Society: Series B (Statistical Methodology), 83(1):188–212, 2021. &lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Gabriel Goh. Why momentum really works. Distill, 2(4):e6, 2017. &lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:15&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Osman Guler. New proximal point algorithms for convex minimization. ¨ SIAM Journal on Optimization, 2(4):649–664, 1992. &lt;a href=&#34;#fnref:15&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Fast Quantum State Tomography via Accelerated Non-convex Programming</title>
      <link>https://jlylekim.github.io/blog/acc-qst/</link>
      <pubDate>Wed, 17 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://jlylekim.github.io/blog/acc-qst/</guid>
      <description>&lt;p&gt;This blog post is about my recent work on quantum state tomography using (accelerated) non-convex programming,&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; published in &lt;a href=&#34;https://www.mdpi.com/2304-6732/10/2/116&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Photonics 2023&lt;/a&gt;. This is a joint work with my advisor &lt;a href=&#34;https://akyrillidis.github.io/about/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prof. Tasos Kyrillidis&lt;/a&gt; at Rice University, &lt;a href=&#34;https://scholar.google.com/citations?user=te_1dnAAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Amir Kalev&lt;/a&gt; at USC, and &lt;a href=&#34;https://researcher.watson.ibm.com/researcher/view.php?person=us-gkollias&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Georgios Kollias&lt;/a&gt; and &lt;a href=&#34;https://scholar.google.com/citations?user=9uuZX3IAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. Ken Wei&lt;/a&gt; at IBM Quantum.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Quantum state tomography (QST) is one of the main procedures to identify the nature of imperfections in quantum processing unit (QPU) implementation. Just like electrical engineers used multimeters and ascilloscopes to verify that circuits work as expected in building classical computers, we need similar verification tools in building quantum computers. QST is one such tool.
High-level procedure of QST is to measure the quantum system represented by a density matrix (a PSD matrix with unit trace), estimate the density matrix using the measured data, and then analyze the &amp;ldquo;fit&amp;rdquo; between the estimated density matrix and the true.&lt;/p&gt;
&lt;p&gt;Before studying how QST is performed, let&amp;rsquo;s start by defining the basic notions. In classical computing, the most fundamental unit of computation are bits, which can be either $0$. or $1$. Analoguous notion in quantum computing is called &lt;em&gt;qubits&lt;/em&gt;, short for &amp;ldquo;quantum bits.&amp;rdquo; However, qubits are represented by 2-dimensional unit vectors:
\begin{align*}
|0 \rangle = [1 ~~ 0 ]^\top, ~~~\text{and}~~~ |1 \rangle = [0 ~~ 1 ]^\top.
\end{align*}
One of the main difference between classical computing and quantum computing is that, unlike a classical bit which can either be 0 or 1, a single qubit state $|\Psi\rangle$ can be in the &amp;ldquo;superposition&amp;rdquo; of $|0\rangle$ and $|1\rangle$, i.e., $| \Psi \rangle = \alpha |0 \rangle + \beta |1 \rangle$, where $\alpha$ and $\beta$ are called the &amp;ldquo;probability amplitudes,&amp;rdquo; and are complex numbers. Geometrically, it can be reprensented as a point in the unit sphere, known as the &amp;ldquo;bloch sphere&amp;rdquo; in quantum computing, illustrated below:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-bloch-sphere-figure-source-httpsenwikipediaorgwikibloch_spheremediafilebloch_spheresvg&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/bloch_hu1fdbbe82f8d04bc229a0ea2e51146515_69402_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Bloch sphere. Figure source: &amp;lt;a href=&amp;#34;https://en.wikipedia.org/wiki/Bloch_sphere#/media/File:Bloch_sphere.svg&amp;#34;&amp;gt;https://en.wikipedia.org/wiki/Bloch_sphere#/media/File:Bloch_sphere.svg&amp;lt;/a&amp;gt;&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/bloch_hu1fdbbe82f8d04bc229a0ea2e51146515_69402_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;35%&#34; height=&#34;877&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Bloch sphere. Figure source: &lt;a href=&#34;https://en.wikipedia.org/wiki/Bloch_sphere#/media/File:Bloch_sphere.svg&#34;&gt;https://en.wikipedia.org/wiki/Bloch_sphere#/media/File:Bloch_sphere.svg&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Once we &amp;ldquo;measure&amp;rdquo; the state $|\Psi\rangle$, it collapses to the $| 0\rangle$ state with probability $|\alpha|^2$, and to the $1 \rangle$ state with probability $|\beta|^2$.&lt;/p&gt;
&lt;h3 id=&#34;qst-for-a-single-qubit-state&#34;&gt;QST for a single qubit state&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s now look at how QST is performed for a single qubit state. Any single qubit state can be written as
\begin{align*}
\rho = \frac{1}{2} \left( I + r_x \sigma_x + r_y \sigma_y + r_z \sigma_z \right),
\end{align*}
where $\sigma_x$, $\sigma_y$, and $\sigma_z$ are &lt;a href=&#34;https://en.wikipedia.org/wiki/Pauli_matrices&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pauli matrices&lt;/a&gt;. the quantity $r_\alpha = \text{Tr}(\rho \sigma_\alpha)$ for $\alpha=x, y, z$ is called the expectation value of $\sigma_\alpha$ with respect to $\rho$. From the above form, we can see that as long as we can estimate the expectation values, we can reconstruct $\rho$. So how do we measure or estimate the expectation values?&lt;/p&gt;
&lt;p&gt;It turns out that we cannot measure it right away, but needs to go through a sequence of steps, as below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prepare $M$ number of copies of the state $\rho$&lt;/li&gt;
&lt;li&gt;Measure the projection of $\rho$ onto eigenvectors of $\sigma_\alpha$, resulting in $\alpha_1, \dots, \alpha_M$.&lt;/li&gt;
&lt;li&gt;Approximation of $\text{Tr} (\rho \sigma_\alpha)$ is given by $\frac{1}{M} \sum_{i=1}^M \alpha_i$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To understand better, let&amp;rsquo;s consider an example, with the visual aid of the block sphere in the above figure.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For simplicity, let&amp;rsquo;s consider estimating $r_z$ ($r_x$ and $r_y$ can be estimated similarly).&lt;/li&gt;
&lt;li&gt;Assume we prepared $M=1000$ copies of the state $|\Psi\rangle$, which collapsed to $|0_z\rangle$ 400 times, and $|1_z\rangle$ 600 times.&lt;/li&gt;
&lt;li&gt;Then, we can compute the empirical frequencies
$\texttt{Tr}\left(\rho |0_z \rangle \langle 0_z | \right) \approx \tfrac{400}{1000} := y_0^z$ and $\texttt{Tr}\left(\rho |1_z \rangle \langle 1_z | \right) \approx \tfrac{600}{1000} := y_1^z$&lt;/li&gt;
&lt;li&gt;Finally, we can estimate $\hat{r}_z = y_0^z - y_1^z$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By repeating the above procedure for $r_x$ and $r_y$, we have performed a single qubit QST. Mathematically, we can solve the following optimization problem:
\begin{align}
&amp;amp; \underset{\rho \in \mathbb{C}^{d \times d}}{\text{minimize}}
&amp;amp; &amp;amp; f(\rho) := \sum_{\alpha=x, y, z} \sum_{i=0,1} \left( \texttt{Tr}(\rho A_i^\alpha) - y_i^\alpha \right)^2 \\&lt;br&gt;
&amp;amp; \text{subject to}
&amp;amp; &amp;amp; \rho \succeq 0,~\texttt{Tr}(\rho) = 1,
\end{align}
where the PSD constraint ($\rho \succeq 0$) and the unit trace constraint ($\texttt{Tr}(\rho) = 1$) arise from the definition of a density matrix $\rho$.&lt;/p&gt;
&lt;h3 id=&#34;computational-bottlenecks-and-low-rank-prior&#34;&gt;Computational bottlenecks and low-rank prior&lt;/h3&gt;
&lt;p&gt;QST is generally not scalable due to two bottlenecks: $i)$ large data has to be collected to perform tomography; and $ii)$ the space of density matrices grows exponentially (a density matrix $\rho$ of $n$-qubit is of $2^n \times 2^n$ dimensional), from which the one that is consistent with the data has to be found.&lt;/p&gt;
&lt;p&gt;To address the first bottleneck, prior information is often assumed and leveraged to reduce the number of data required. For example, in compressed sensing QST, &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; it assumes that the density matrix is of low-rank, which physically means the state is close to a &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_state&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pure state&lt;/a&gt;.&lt;/p&gt;
&lt;!-- Similarly, in neural network QST, the wavefunctions are assumed to be real and positive. [^torlai2018neural] [^torlai2019machine] [^beach2019qucumber] --&gt;
&lt;p&gt;To give a concrete example, in the figure below, real (top) and imaginary (bottom) parts of four different states are shown: $i)$ $\texttt{GHZ}$ state, $ii)$ $\texttt{GHZminus}$ state, $iii)$ $\texttt{Hadamard}$ state, and $iv)$ $\texttt{Random}$ state; for the mathematical description of the above states, refer to our paper. &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; As can be seen, for $\texttt{GHZ}$ and $\texttt{GHZminus}$ states, only four corners of the real parts have non-zero entries. Therefore, the density matrices are not only of low-rank, but also sparse. Similarly, $\texttt{Hadamard}$ has uniform entries in the real part, which can be written as a $\text{rank-}1$ matrix.
If these structures are smartly leveraged, one can sometimes confine the search space of density matrices greatly, leading to less number of measurements required for successful tomography results. In particular, it was proven that one can reconstruct a rank-$r$ density matrix using $O(r \cdot d \cdot \text{poly} \log d)$ measurements.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-from-left-to-right-textttghz-textttghzminus-texttthadamard-and-textttrandom-states-all-states-are-in-4-qubit-system&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/state-plots_hu9736c4582f4c1c7a26a8563df014da3f_333023_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;From left to right: $\texttt{GHZ}$, $\texttt{GHZminus}$, $\texttt{Hadamard}$, and $\texttt{Random}$ states. All states are in 4-qubit system.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/state-plots_hu9736c4582f4c1c7a26a8563df014da3f_333023_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;411&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    From left to right: $\texttt{GHZ}$, $\texttt{GHZminus}$, $\texttt{Hadamard}$, and $\texttt{Random}$ states. All states are in 4-qubit system.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;With regards to the second bottleneck, variants of gradient descent convex solvers were proposed under synthetic scenarios. &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; However, due to the exponentially increasing space of density matrices, these methods often can be only applied to relatively small system, on top of relying on special-purpose hardwares and proper distributed system designs.&lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;On the contrary, non-convex optimization methods can perform much faster. It was recently shown that one can formulate compressed sensing QST as a non-convex problem,&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt; which can be solved with rigorous convergence guarantees, allowing density matrix estimation in a large system. A relevant result can be seen in the &lt;strong&gt;Results&lt;/strong&gt; section below, where we compare our proposed (accelerated) non-convex method with &lt;a href=&#34;https://qiskit.org/documentation/stubs/qiskit.ignis.verification.TomographyFitter.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;convex methods from $\texttt{Qiskit}$&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this work, we consider the setup where $n$-qubit state is close to a pure state, thus its density matrix is of low-rank. We introduce an accelerated non-convex algorithm with provable gaurantees, which we call $\texttt{MiFGD}$, short for &amp;ldquo;$\texttt{M}$omentum $\texttt{i}$nspired $\texttt{F}$actored $\texttt{G}$radient $\texttt{D}$escent.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;problem-setup&#34;&gt;Problem setup&lt;/h2&gt;
&lt;p&gt;We consider the reconstruction of a low-rank density matrix $\rho^\star \in \mathbb{C}^{d \times d}$ on a $n$-qubit Hilbert space, where $d=2^n$, through the following $\ell_2$-norm reconstruction objective:&lt;/p&gt;
&lt;p&gt;\begin{align}
\label{eq:objective} \tag{1}
\min_{\rho \in \mathbb{C}^{d \times d}}
\quad &amp;amp; f(\rho) := \tfrac{1}{2} ||\mathcal{A}(\rho) - y||_2^2 \\&lt;br&gt;
\text{subject to}
\quad&amp;amp; \rho \succeq 0, ~\texttt{rank}(\rho) \leq r.
\end{align}&lt;/p&gt;
&lt;p&gt;Here, $y \in \mathbb{R}^m$ is the measured data through quantum computer or simulation, and $\mathcal{A}(\cdot): \mathbb{C}^{d \times d} \rightarrow \mathbb{R}^m$ is the linear sensing map. The sensing map relates the density matrix $\rho$ to the measurements through &lt;a href=&#34;https://en.wikipedia.org/wiki/Born_rule&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Born rule&lt;/a&gt;: $\left( \mathcal{A}(\rho) \right)_i = \text{Tr}(A_i \rho),$ where $A_i \in \mathbb{C}^{d \times d},~i=1, \dots, m$ are the sensing matrices. &lt;!--Type of sensing matrices used in quantum state tomography will be discussed later.--&gt; From the objective function above, we see two constraints: $i)$ the density matrix $\rho$ is a positive semidefinite matrix (which is a convex constraint), and $ii)$ the rank of the density matrix is less than $r$ (which is a non-convex constraint).&lt;/p&gt;
&lt;p&gt;As mentioned earlier, we focus on &lt;em&gt;compressed sensing quantum state tomography&lt;/em&gt; setting, where the number of measured data $m$ is much smaller than the problem dimension $O(d^2)$. Compressed sensing is a powerful optimization framework developed mainly by &lt;a href=&#34;https://statweb.stanford.edu/~candes/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Emmanuel Candès&lt;/a&gt;, &lt;a href=&#34;https://jrom.ece.gatech.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Justin Romberg&lt;/a&gt;, &lt;a href=&#34;https://www.math.ucla.edu/~tao/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Terence Tao&lt;/a&gt; and &lt;a href=&#34;https://web.stanford.edu/dept/statistics/cgi-bin/donoho/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Donoho&lt;/a&gt;, and requires the following pivotal assumption on the sensing matrix $\mathcal{A}(\cdot)$, namely the &lt;strong&gt;Restricted Isometry Property (RIP)&lt;/strong&gt; (on $\texttt{rank}$-$r$ matrices): &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;\begin{align}
\label{eq:rip} \tag{2}
(1 - \delta_r) \cdot  || X ||_F^2 \leq || \mathcal{A}(X) ||_2^2 \leq (1 + \delta_r) \cdot ||X||_F^2.
\end{align}&lt;/p&gt;
&lt;p&gt;Intuitively, the above RIP assumption states that the sensing matrices $\mathcal{A}(\cdot)$ only &amp;ldquo;marginally&amp;rdquo; changes the norm of the matrix $X$.&lt;/p&gt;
&lt;p&gt;Going back to the main optimization problem in Eq. \eqref{eq:objective}, instead of solving it as is, we propose to solve a factorized version of it, following recent work &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;:
\begin{align}
\label{eq:factored-obj} \tag{3}
\min_{U \in \mathbb{C}^{d \times r}} f(UU^\dagger) := \tfrac{1}{2} || \mathcal{A} (UU^\dagger) - y ||_2^2,
\end{align}
where $U^\dagger$ denotes the &lt;a href=&#34;https://en.wikipedia.org/wiki/Conjugate_transpose&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;adjoint&lt;/a&gt; of $U$. The motivation is rather clear: in the original objective function in Eq. \eqref{eq:objective}, the density matrix $\rho$ is represented as a $d \times d$ Hermitian matrix, and due to the (non-convex) $\texttt{rank}(\cdot)$ constraint, some method to project onto the set of low-rank matrices is required. Instead, we work in the space of the factors $U \in \mathbb{C}^{d \times r}$, and by taking an outer-product, the $\texttt{rank}(\cdot)$ constraint and the PSD constraint $\rho \succeq 0$ are automatically satisfied, leading to the non-convex formulation in Eq. \eqref{eq:factored-obj}. But how do we solve such problem?&lt;/p&gt;
&lt;p&gt;A common approach is to use gradient descent on $U$, which iterates as follows:
\begin{align}
\label{eq:fgd} \tag{4}
U_{i+1} &amp;amp;= U_{i} - \eta \nabla f(U_i U_i^\dagger) \cdot U_i \\&lt;br&gt;
&amp;amp;= U_{i} - \eta \mathcal{A}^\dagger \left(\mathcal{A}(U_i U_i^\dagger) - y\right) \cdot U_i.
\end{align}&lt;/p&gt;
&lt;!--HERE IT IS NOT CLEAR WHAT IS f - DEFINE IT IN EQ.(3).--&gt;
&lt;p&gt;Here, $\mathcal{A}^\dagger: \mathbb{R}^m \rightarrow \mathbb{C}^{d \times d}$ is the adjoint of $\mathcal{A}$, defined as $\mathcal{A}^\dagger = \sum_{i=1}^m x_i A_i.$ $\eta$ is a hyperparameter called step size or learning rate. This method is called &amp;ldquo;$\texttt{F}$actored $\texttt{G}$radient $\texttt{D}$escent&amp;rdquo; ($\texttt{FGD}$), and was utilized to solve the non-convex objective function in Eq. \eqref{eq:factored-obj}, (surprisingly) with provable gaurantees.&lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;momentum-inspired-factored-gradient-descent&#34;&gt;Momentum-inspired Factored Gradient Descent&lt;/h2&gt;
&lt;p&gt;Momentum is one of the de facto techniques to achieve acceleration in gradient descent type of algorithms. Acceleration methods exist in various forms, including Polyak&amp;rsquo;s momentum, Nesterov&amp;rsquo;s acceleration, classical momentum, etc. They end up behaving pretty similarly, and we will not get into the detail of different acceleration methods in this post. For interested readers, I recommend this &lt;a href=&#34;https://jlmelville.github.io/mize/nesterov.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blog post&lt;/a&gt; by James Melville.&lt;/p&gt;
&lt;p&gt;A common feature accross acceleration methods is that, with proper hyper-parameter tuning, they can provide accelerated convergence rate with virtually no additional computation. This is exactly the motivation of the $\texttt{MiFGD}$ algorithm we propose for solving the non-convex objective in Eq. \eqref{eq:factored-obj}, and the algorithm proceeds as follows:
\begin{align}
\label{eq:mifgd} \tag{5}
U_{i+1} &amp;amp;= Z_{i} - \eta \mathcal{A}^\dagger \left(\mathcal{A}(Z_i Z_i^\dagger) - y\right) \cdot Z_i, \\&lt;br&gt;
Z_{i+1} &amp;amp;= U_{i+1} + \mu \left(U_{i+1} - U_i\right).
\end{align}&lt;/p&gt;
&lt;p&gt;Here, $Z_i \in \mathbb{C}^{d\times r}$ is a rectangular matrix (with the same dimension as $U_i$) which accumulates the &amp;ldquo;momentum&amp;rdquo; of the iterates $U_i$. $\mu$ is the momentum parameter that balances the weight between the previous estimate $U_i$ and the current estimate $U_{i+1}.$&lt;/p&gt;
&lt;p&gt;While the $\texttt{MiFGD}$ algorithm in Eq. \eqref{eq:mifgd} looks quite similar to $\texttt{FGD}$ in Eq. \eqref{eq:fgd}, it complicates the convergence theory significantly. This is because the two-step momentum procedure has to be considered, on top of the fact that the objective function in Eq. \eqref{eq:factored-obj} is non-convex. We will not get into the details of the convergence thoery here; interested readers are referred to our paper.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; We finish this section with an informal theorem that illustrates the convergence behavior of $\texttt{MiFGD}$:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem 1&lt;/strong&gt; ($\texttt{MiFGD}$ convergence rate (informal)). Assume that $\mathcal{A}(\cdot)$ satisfies the RIP for some constant $0 &amp;lt; \delta_{2r} &amp;lt;1$. Let $y = \mathcal{A}(\rho^\star)$ denote the set of measurements, by measuring the quantum density matrix $\rho^\star$. Given a good initialization point $U_0$, and setting step size $\eta$ and momentum $\mu$ appropriately, $\texttt{MiFGD}$ converges with a linear rate to a region—with radius that depends on $O(\mu)$—around the global solution $\rho^\star$.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;In this section, we review some of the experimental results. First, we obtain real quantum data from IBM&amp;rsquo;s Quantum Processing Unit (QPU) by realizing two types of quantum states: $\texttt{GHZminus}(n)$ and $\texttt{Hadamard}(n)$, for $n = 6, 8$, where $n$ is the number of qubits. In quantum computing, obtaining measurements itself is not a trivial process, which we will not get into the detail in this post. Yet, we highlight that, in the following plots, we only use $20$% of the measurements that are information-theoretically compelete, i.e. we sample $m = 0.2 \cdot d^2$ measurements (recall that we are working on compressed sensing QST setting). We compare the effect of different momentum parameters in the figure below, where the accuracy of the estimated density matrix $\widehat{\rho}$ is measured with the true density matrix $\rho^\star$ in terms of the squared Frobenius norm, i.e. $||\widehat{\rho} - \rho^\star||_F^2$:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-textttmifgd-performance-on-real-quantum-data-from-ibm-qpu-top-left-textttghzminus6-top-right-textttghzminus8-bottom-left-texttthadamard6-bottom-right-texttthadamard8&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/ibm-data_hu9ed558def99604cea272504d5b0afe6e_128657_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;$\texttt{MiFGD}$ performance on real quantum data from IBM QPU. Top-left: $\texttt{GHZminus}(6)$, Top-right: $\texttt{GHZminus}(8)$, Bottom-left: $\texttt{Hadamard(6)}$, Bottom-right: $\texttt{Hadamard}(8)$.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/ibm-data_hu9ed558def99604cea272504d5b0afe6e_128657_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;545&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    $\texttt{MiFGD}$ performance on real quantum data from IBM QPU. Top-left: $\texttt{GHZminus}(6)$, Top-right: $\texttt{GHZminus}(8)$, Bottom-left: $\texttt{Hadamard(6)}$, Bottom-right: $\texttt{Hadamard}(8)$.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Above figure summarizes the performance of $\texttt{MiFGD}$. In the legends, $\mu^\star$ is the momentum parameter proposed by our theory; however, it should be noted that $\texttt{MiFGD}$ converges with larger momentum values than $\mu^\star$, in particular featuring a steep dive to convergence for the largest value of $\mu$ we tested. Moreover, the above figure also highlights the universality of our approach: its performance is oblivious to the quantum state reconstructed, as long as it satisfies purity or it is close to a pure state. Our method does not require any additional structure assumptions in the quantum state.&lt;/p&gt;
&lt;p&gt;It should be noted that quantum data are inherently noisy. To highlight the level of noise existing in real quantum data, in the figure below, we also plot the performance of $\texttt{MiFGD}$ in the same setting using simulated quantum data from IBM&amp;rsquo;s &lt;a href=&#34;https://github.com/Qiskit/openqasm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;QASM&lt;/a&gt; simulator:  &lt;!--in $\texttt{qiskit-aer}$.--&gt;&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-textttmifgd-performance-on-synthetic-data-using-ibms-qasm-simulator-top-left-textttghzminus6-top-right-textttghzminus8-bottom-left-texttthadamard6-bottom-right-texttthadamard8&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/simulator-data_hu1586622ad382eaa8ab67ffb7b3e9beca_132295_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;$\texttt{MiFGD}$ performance on synthetic data using IBM&amp;amp;rsquo;s QASM simulator. Top-left: $\texttt{GHZminus}(6)$, Top-right: $\texttt{GHZminus}(8)$, Bottom-left: $\texttt{Hadamard(6)}$, Bottom-right: $\texttt{Hadamard}(8)$.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/simulator-data_hu1586622ad382eaa8ab67ffb7b3e9beca_132295_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;60%&#34; height=&#34;545&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    $\texttt{MiFGD}$ performance on synthetic data using IBM&amp;rsquo;s QASM simulator. Top-left: $\texttt{GHZminus}(6)$, Top-right: $\texttt{GHZminus}(8)$, Bottom-left: $\texttt{Hadamard(6)}$, Bottom-right: $\texttt{Hadamard}(8)$.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We see a similar trend with the result using real quantum data from IBM&amp;rsquo;s QPU. However, we see that the overall accuracy of the reconstucted and the target states, $|| \hat{\rho} - \rho^\star||_F^2$, is generally lower for the real quantum data&amp;ndash;they do not reach the accuracy level of $10^{-1}$, which is acchieved for all cases using QASM simulator. This difference is summarized in the figure below:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-final-fidelity-of-textttmifgd-comparison-using-real-quantum-data-from-ibms-qpu-and-simulated-quantum-data-using-qasm&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/qpu-vs-qasm_hu5758ce60bc0bf36c5fbb63063c04e7bf_40419_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Final fidelity of $\texttt{MiFGD}$ comparison using real quantum data from IBM&amp;amp;rsquo;s QPU and simulated quantum data using QASM.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/qpu-vs-qasm_hu5758ce60bc0bf36c5fbb63063c04e7bf_40419_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;225&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Final fidelity of $\texttt{MiFGD}$ comparison using real quantum data from IBM&amp;rsquo;s QPU and simulated quantum data using QASM.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;performance-comparison-with-qst-methods-in-textttqiskit&#34;&gt;Performance comparison with QST methods in $\texttt{Qiskit}$&lt;/h4&gt;
&lt;p&gt;Now, we compare the performance of $\texttt{MiFGD}$ with &lt;a href=&#34;https://qiskit.org/documentation/stubs/qiskit.ignis.verification.TomographyFitter.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;QST methods&lt;/a&gt; from &lt;a href=&#34;https://qiskit.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;$\texttt{Qiskit}$&lt;/a&gt;, again using IBM&amp;rsquo;s QASM simulator. $\texttt{Qiskit}$ provides two QST methods: $i)$ the $\texttt{CVXPY}$ method which relies on convex optimiztion, and $ii)$ the $\texttt{lstsq}$ which ruses least-squares fitting. Both methods solve the following full tomography problem (not compressed sensing QST problem):&lt;/p&gt;
&lt;p&gt;\begin{align}
\min_{\rho \in \mathbb{C}^{d \times d}}
\quad &amp;amp; f(\rho) := \tfrac{1}{2} ||\mathcal{A}(\rho) - y||_2^2 \\&lt;br&gt;
\text{subject to}
\quad &amp;amp; \rho \succeq 0, ~\texttt{Tr}(\rho) = 1.
\end{align}&lt;/p&gt;
&lt;p&gt;We note that $\texttt{MiFGD}$ is not restricted to ``tall&#39;&#39; $U$ scenarios to encode PSD and rank constraints: even without rank constraints, one could still exploit the matrix decomposition $\rho = UU^\dagger$ to avoid the PSD projection, $\rho \succeq 0$, where $U \in \mathbb{C}^{d \times d}$.&lt;/p&gt;
&lt;p&gt;We consider the following cases: $\texttt{GHZ}(n), \texttt{Hadamard}(n),$ and $\texttt{Random}(n)$ for $n = 3, \dots, 8$.
The results are shown in the figure below:&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-performance-comparison-with-textttqiskit-methods-all-experiments-are-performed-on-a-13-macbook-pro-with-23-ghz-quad-core-intel-core-i7-cpu-and-32-gb-ram&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/qiskit-comparison-plot_hu2d6d342ea7df9de5cc271429d5df76e2_87716_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Performance comparison with $\texttt{Qiskit}$ methods. All experiments are performed on a 13” Macbook Pro with 2.3 GHz Quad-Core Intel Core i7 CPU and 32 GB RAM.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/qiskit-comparison-plot_hu2d6d342ea7df9de5cc271429d5df76e2_87716_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;354&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Performance comparison with $\texttt{Qiskit}$ methods. All experiments are performed on a 13” Macbook Pro with 2.3 GHz Quad-Core Intel Core i7 CPU and 32 GB RAM.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Some notable remarks: $i)$ For small-scale scenarios ($n=3, 4$), $\texttt{CVXPY}$ and $\texttt{lstsq}$ attain almost perfect fidelity, while being comparable or faster than $\texttt{MiFGD}$. $ii)$ The difference in performance becomes apparent from $n = 6$ and on: while $\texttt{MiFGD}$ attains $98$% fidelity in less than $5$ seconds, $\texttt{CVXPY}$ and $\texttt{lstsq}$ require up to hundreds of seconds to find a good solution. Finally, while $\texttt{MiFGD}$ gets to high-fidelity solutions in seconds for $n = 7, 8$, $\texttt{CVXPY}$ and $\texttt{lstsq}$ methods require more than 12 hours execution time; however, their execution never ended, since the memory usage exceeded the system&amp;rsquo;s available memory.&lt;/p&gt;
&lt;h4 id=&#34;performance-comparison-with-neural-network-qst-using-textttqucumber&#34;&gt;Performance comparison with neural-network QST using $\texttt{Qucumber}$&lt;/h4&gt;
&lt;p&gt;Next, we compare the performance of $\texttt{MiFGD}$ compare with neural-network based QST methods, proivded by &lt;a href=&#34;https://qucumber.readthedocs.io/en/stable/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;$\texttt{Qucumber}$&lt;/a&gt;. We consider the same quantum states as with $\texttt{Qiskit}$ experiments, but here we consider the case where only $50$% of the measurements are available.&lt;/p&gt;
&lt;p&gt;We report the fidelity of the reconstruction as a function of elapsed training time for $n = 3, 4$ in the figure below for all methods provided by $\texttt{Qucumber}$: $\texttt{PRWF}, \texttt{CWF}$, and $\texttt{DM}$. Note that Time (secs) on $x$-axis is plotted with log-scale.&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-performance-comparison-with-textttqucumber-methods-all-experiments-are-performed-on-a-nvidia-geforce-gtx-1080-ti-with-11gb-ram&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/nn-comparison-plot_hu644a7db2c2bfa79e3f8214cbba60fb92_97789_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Performance comparison with $\texttt{Qucumber}$ methods. All experiments are performed on a NVidia GeForce GTX 1080 TI with 11GB RAM.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/nn-comparison-plot_hu644a7db2c2bfa79e3f8214cbba60fb92_97789_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;408&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Performance comparison with $\texttt{Qucumber}$ methods. All experiments are performed on a NVidia GeForce GTX 1080 TI with 11GB RAM.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We observe that for all cases, $\texttt{Qucumber}$ methods are orders of magnitude slower than $\texttt{MiFGD}$.
For the $\texttt{Hadamard}(n)$ and $\texttt{Random}(n)$, reaching reasonable fidelities is significantly slower for both $\texttt{CWF}$ and $\texttt{DM},$ while $\texttt{PRWF}$ hardly improves its performance throughout the training.
For the $\texttt{GHZ}$ case, $\texttt{CWF}$ and $\texttt{DM}$ also shows &lt;em&gt;non-monotonic&lt;/em&gt; behaviors: even after a few thousands of seconds, fidelities have not &amp;ldquo;stabilized&amp;rdquo;, while $\texttt{PRWF}$ stabilizes in very low fidelities.
In comparison, $\texttt{MiFGD}$ is several orders of magnitude faster than both $\texttt{CWF}$ and $\texttt{DM}$ and fidelity smoothly increases to comparable or higher values. What is notable is the scalability of $\texttt{MiFGD}$ compared to neural network approaches for higher values of $n$.&lt;/p&gt;
&lt;p&gt;To see this more clearly, in the table below, we report the final fidelities (within the $3$ hour time window), and reported times. We see that for many cases, $\texttt{CWF}$ and $\texttt{DM}$ methods did not complete a single iterations within $3$ hours.&lt;/p&gt;
&lt;!-- For a stark contrast,  $\texttt{MiFGD}$ for $n=8$ took less than 25 seconds, while $\texttt{PRWF}$, which is the fastest neural-network method provided by $\texttt{Qucumber}$, took more than 40 seconds for $n=3$. --&gt;






  



  
  











&lt;figure id=&#34;figure-comparison-with-qucumber-methods&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/nn-comparison_hua17c2be52f23f3de862b40367885380f_171885_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Comparison with Qucumber methods.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/nn-comparison_hua17c2be52f23f3de862b40367885380f_171885_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;70%&#34; height=&#34;740&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Comparison with Qucumber methods.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;the-effect-of-parallelization-in-textttmifgd&#34;&gt;The effect of parallelization in $\texttt{MiFGD}$&lt;/h4&gt;
&lt;p&gt;We also study the effect of paralleization in running $\texttt{MiFGD}$. We parallelize the iteration step across a number
of processes, that can be either distributed and network connected, or sharing memory in a multicore environment.
Our approach is based on &lt;a href=&#34;https://en.wikipedia.org/wiki/Message_Passing_Interface&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Message Passing Interface (MPI)&lt;/a&gt; specification. We assign to each process a subset of the measurement labels consumed by the parallel computation. At each step, a process first computes the local gradient using a subset of measurements. These local gradients are then communicated so that they can be added up to form the full gradient, and the full gradient is shared with each worker.&lt;/p&gt;
&lt;p&gt;In our first round of experiments, we investigate the scalability of the parallelization approach. We vary the number $p$ of parallel processes $(p=1, 2, 4, 8, 16, 32, 48, 64, 80, 96)$, collect timings for reconstructing $\texttt{GHZ}(4)$, $\texttt{Random}(6)$ and $\texttt{GHZminus}(8)$ states, and report speedups $T_p/T_1$ we gain from $\texttt{MiFGD}$ in the figure bloew (left panel). We observe that the benefits of parallelization are pronounced for bigger problems (here: $n=8$ qubits) and maximum scalability results when we use all physical cores ($48$ in our platform).&lt;/p&gt;






  



  
  











&lt;figure id=&#34;figure-effect-of-parallelization-of-textttmifgd-left-scalability-of-parallelization-of-textttmifgd-for-different-number-of-processors-middle-fidelity-versus-time-consued-for-different-number-of-processors-on-texttthadamard10-state-right-the-effect-of-momentum-on-texttthadamard10-state-with-48-processors&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://jlylekim.github.io/blog/acc-qst/parallel_hub9237cb47336b5cec8dd803d37ed29cf_49045_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;Effect of parallelization of $\texttt{MiFGD}$. Left: scalability of parallelization of $\texttt{MiFGD}$ for different number of processors. Middle: fidelity versus time consued for different number of processors on $\texttt{Hadamard}(10)$ state. Right: The effect of momentum on $\texttt{Hadamard}(10)$ state with 48 processors.&#34;&gt;


  &lt;img data-src=&#34;https://jlylekim.github.io/blog/acc-qst/parallel_hub9237cb47336b5cec8dd803d37ed29cf_49045_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;100%&#34; height=&#34;210&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Effect of parallelization of $\texttt{MiFGD}$. Left: scalability of parallelization of $\texttt{MiFGD}$ for different number of processors. Middle: fidelity versus time consued for different number of processors on $\texttt{Hadamard}(10)$ state. Right: The effect of momentum on $\texttt{Hadamard}(10)$ state with 48 processors.
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Further, we move to larger problems ($n=10$ qubits: reporting on reconstructing $\texttt{Hadamard}(10)$ state) and focus on the effect parallelization to achieving a given level of fidelity in reconstruction. In the middle panel of the figure above, we illustrate the fidelity as a function of the time spent in the iteration loop of $\texttt{MiFGD}$ for ($p=8, 16, 32, 48, 64$): we observe the smooth path to convergence in all $p$ counts which again minimizes compute time for $p=48$. Note that in this case we use $10$% of the complete measurements, and the momenutum parameter $\mu=\frac{1}{4}$.&lt;/p&gt;
&lt;p&gt;Finally, in the right panel of the figure above, we fix the number of processes to $p=48$, in order to minimize compute time and increase the percentage of used measurements to $20$% of the complete measurements available for $\texttt{Hadamard}(10)$. We vary the momentum parameter from $\mu=0$ (no acceleration) to $\mu=\frac{1}{4}$, and confirm that we indeed get faster convergence times in the latter case while the fidelity value remains the same (i.e. coinciding upper plateau value in the plots). We can also compare with the previous fidelity versus time plot, where the same $\mu$ but half the measurements are consumed: more measurements translate to faster convergence times (plateau is reached roughly $25$% faster; compare the green line with the yellow line in the previous plot).&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have introduced the $\texttt{MiFGD}$ algorithm for the factorized form of the low-rank QST problems.
We proved that, under certain assumptions on the problem parameters, $\texttt{MiFGD}$ converges linearly to a neighborhood of the optimal solution, whose size depends on the momentum parameter $\mu$, while using acceleration motions in a non-convex setting.
We demonstrate empirically, using both simulated and real data, that $\texttt{MiFGD}$ outperforms non-accelerated methods on both the original problem domain and the factorized space, contributing to recent efforts on testing QST algorithms in real quantum data.
These results expand on existing work in the literature illustrating the promise of factorized methods for certain low-rank matrix problems.
Finally, we provide a publicly available implementation of our approach, compatible to the open-source software $\texttt{Qiskit}$, where we further exploit parallel computations in $\texttt{MiFGD}$ by extending its implementation to enable efficient, parallel execution over shared and distributed memory systems.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Junhyung Lyle Kim, George Kollias, Amir Kalev, Ken X. Wei, Anastasios Kyrillidis. Fast quantum state reconstruction via accelerated non-convex programming. Photonics, 10(2), 2023. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Gross, Y.-K. Liu, S. Flammia, S. Becker, and J. Eisert. Quantum state tomography via compressed
sensing. Physical review letters, 105(15):150401, 2010. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Kalev, R. Kosut, and I. Deutsch. Quantum tomography protocols with positivity are compressed
sensing protocols. NPJ Quantum Information, 1:15018, 2015. &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;D. Gonçalve, M. Gomes-Ruggiero, and C. Lavor. A projected gradient method for optimization over
density matrices. Optimization Methods and Software, 31(2):328–341, 2016. &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;E. Bolduc, G. Knee, E. Gauger, and J. Leach. Projected gradient descent algorithms for quantum state tomography. npj Quantum Information, 3(1):44, 2017. &lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Jiangwei Shang, Zhengyun Zhang, and Hui Khoon Ng. Superfast maximum-likelihood reconstruction
for quantum tomography. Phys. Rev. A, 95:062336, Jun 2017. &lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zhilin Hu, Kezhi Li, Shuang Cong, and Yaru Tang. Reconstructing pure 14-qubit quantum states in
three hours using compressive sensing. IFAC-PapersOnLine, 52(11):188 – 193, 2019. 5th IFAC Conference on Intelligent Control and Automation Sciences ICONS 2019. &lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zhibo Hou, Han-Sen Zhong, Ye Tian, Daoyi Dong, Bo Qi, Li Li, Yuanlong Wang, Franco Nori, Guo-Yong Xiang, Chuan-Feng Li, et al. Full reconstruction of a 14-qubit state within four hours. New Journal of Physics, 18(8):083036, 2016. &lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Kyrillidis, A. Kalev, D. Park, S. Bhojanapalli, C. Caramanis, and S. Sanghavi. Provable quantum state tomography via non-convex methods. npj Quantum Information, 4(36), 2018. &lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Benjamin Recht, Maryam Fazel, and Pablo A Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization. SIAM review, 52(3):471–501, 2010. &lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Basics of Quantum Mechanics 2</title>
      <link>https://jlylekim.github.io/blog/quantum-mechanics-2/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://jlylekim.github.io/blog/quantum-mechanics-2/</guid>
      <description>&lt;!-- # Basics of quantum mechanics (part 2) --&gt;
&lt;p&gt;We continue our study of basics of quantum mechanics. Part 1 of this blog series can be found &lt;a href=&#34;https://jlylekim.github.io/post/quantum-mechanics-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;4-matrix-formulation-of-quantum-mechanics&#34;&gt;4. Matrix formulation of quantum mechanics&lt;/h2&gt;
&lt;p&gt;Matrix formulation of quantum mechanics was first proposed by &lt;a href=&#34;https://en.wikipedia.org/wiki/Werner_Heisenberg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Werner Heisenberg&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Max_Born&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Max Born&lt;/a&gt;, and &lt;a href=&#34;https://en.wikipedia.org/wiki/Pascual_Jordan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pascual Jordan&lt;/a&gt;. Later, it was unified with wave mechanics formulation introduced by &lt;a href=&#34;https://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Erwin Schrödinger&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Matrix formulation is particularly useful when we work with finite discrete bases. This is because by using matrix formulation, quantum mechanical quantities can be expressed mostly in matrix multiplication, which is something we understand quite well from linear algebra, and also has been highly optimized both in terms of software (e.g. leveraging structures like sparsity) and hardware (e.g. using GPUs).&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with the basics. Recall that a ket $| \psi \rangle = \sum_i c_i |u_i \rangle$ where $c_i = \langle u_i | \psi \rangle$, which can be thought of as the representation of the ket $|\psi\rangle$ in the ${|u_i\rangle}$ basis. To write the ket $|\psi\rangle$ in matrix form, we simply stack the representation as a column vector as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix}
\langle u_1 | \psi \rangle\\&lt;br&gt;
\langle u_2 | \psi \rangle\\&lt;br&gt;
\vdots\\&lt;br&gt;
\langle u_i | \psi \rangle\\&lt;br&gt;
\vdots
\end{bmatrix}
= \begin{bmatrix}
c_1\\&lt;br&gt;
c_2\\&lt;br&gt;
\vdots\\&lt;br&gt;
c_i\\&lt;br&gt;
\vdots
\end{bmatrix}.
$$&lt;/p&gt;
&lt;p&gt;Similarly, to express a bra $\langle \psi | = \sum_i c_i^* \langle u_i |$ where $c_i^* = \langle \psi | u_i \rangle = \langle u_i | \psi \rangle^*$, we write them as a row vector:&lt;/p&gt;
&lt;p&gt;$$[\langle \psi | u_1 \rangle~\langle \psi | u_2 \rangle \cdots \langle \psi | u_i \rangle \cdots ]
= [c_1^* c_2^* \cdots c_i^* \cdots].
$$&lt;/p&gt;
&lt;p&gt;Now, we look at an operator $\hat{A} = \sum_{ij} A_{ij} |u_i \rangle \langle u_j|$ where $A_{ij} = \langle u_i | \hat{A} | u_j \rangle$, which can be expressed as a matrix:&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix}
A_{11} &amp;amp; A_{12} &amp;amp; \cdots &amp;amp; A_{1j} &amp;amp; \cdots \\&lt;br&gt;
A_{21} &amp;amp; A_{22} &amp;amp; \cdots &amp;amp; A_{2j} &amp;amp; \cdots \\&lt;br&gt;
\vdots &amp;amp; \vdots &amp;amp;  &amp;amp; \vdots &amp;amp;  \\&lt;br&gt;
A_{i1} &amp;amp; A_{i2} &amp;amp; \cdots &amp;amp; A_{ij} &amp;amp; \cdots \\&lt;br&gt;
\vdots &amp;amp; \vdots &amp;amp;  &amp;amp; \vdots &amp;amp;
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;As an example, let&amp;rsquo;s write the expression $|\psi&#39;\rangle = \hat{A} |\psi\rangle$ in terms of matrix formulation. First, recall the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$|\psi&#39;\rangle = \sum_i c_i&#39; |u_i\rangle$&lt;/li&gt;
&lt;li&gt;$|\psi\rangle = \sum_i c_i |u_i\rangle$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, we can express the coefficient $c_i&#39;$ as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
c_i&#39; &amp;amp;= \langle u_i | \psi&#39; \rangle = \langle u_i | \hat{A}| \psi \rangle = \langle u_i | \hat{A} \mathbb{I} | \psi \rangle \\&lt;br&gt;
&amp;amp;= \langle u_i | \hat{A} \left( \sum_j |u_j \rangle \langle u_j | \right) |\psi \rangle = \sum_j \langle u_i | \hat{A} | u_j \rangle \langle u_j | \psi \rangle \\&lt;br&gt;
&amp;amp;= \sum_j A_{ij} c_j.
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;The last expression from the above can be expressed in matrix formulation as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
&amp;amp;\begin{bmatrix}
A_{11} &amp;amp; A_{12} &amp;amp; \cdots &amp;amp; A_{1j} &amp;amp; \cdots \\&lt;br&gt;
A_{21} &amp;amp; A_{22} &amp;amp; \cdots &amp;amp; A_{2j} &amp;amp; \cdots \\&lt;br&gt;
\vdots &amp;amp; \vdots &amp;amp;  &amp;amp; \vdots &amp;amp;  \\&lt;br&gt;
A_{i1} &amp;amp; A_{i2} &amp;amp; \cdots &amp;amp; A_{ij} &amp;amp; \cdots \\&lt;br&gt;
\vdots &amp;amp; \vdots &amp;amp;  &amp;amp; \vdots &amp;amp;
\end{bmatrix}
\cdot
\begin{bmatrix}
c_1\\&lt;br&gt;
c_2\\&lt;br&gt;
\vdots\\&lt;br&gt;
c_i\\&lt;br&gt;
\vdots
\end{bmatrix} =
\begin{bmatrix}
A_{11}c_1 + \dots + A_{1j}c_j \dots \\&lt;br&gt;
A_{21}c_1 + \dots + A_{2j}c_j \dots \\&lt;br&gt;
\vdots\\&lt;br&gt;
A_{i1}c_1 + \dots + A_{ij}c_j \dots \\&lt;br&gt;
\vdots
\end{bmatrix} =
\begin{bmatrix}
c_1&#39;\\&lt;br&gt;
c_2&#39;\\&lt;br&gt;
\vdots\\&lt;br&gt;
c_i&#39;\\&lt;br&gt;
\vdots
\end{bmatrix}
\end{aligned}.
$$&lt;/p&gt;
&lt;p&gt;Therefore, we arrive at the matrix formulation for $c_i&#39;$ we began with. Similarly, we can express other quantum mechanical quantities we have seen in terms of matrix formulation.&lt;/p&gt;
&lt;h2 id=&#34;5-change-of-basis-in-quantum-mechanics&#34;&gt;5. Change of basis in quantum mechanics&lt;/h2&gt;
&lt;p&gt;Recall that we can represent state space with an orthonormal basis. For example, we have been working with the basis ${ | u_i \rangle }$ where $\langle u_i | u_j \rangle = \delta_{ij}$. Then, we can express a ket $|\psi\rangle$ in the ${ |u_i\rangle }$ basis, i.e.&lt;/p&gt;
&lt;p&gt;$$
|\psi \rangle = \sum_i c_i | u_i \rangle \quad\text{where}\quad c_i = \langle u_i | \psi \rangle.
$$&lt;/p&gt;
&lt;p&gt;We will look at how to express the ket $|\psi\rangle$ in different basis, ${ |v_j \rangle }$, i.e.&lt;/p&gt;
&lt;p&gt;$$
|\psi \rangle = \sum_j d_j | v_j \rangle \quad\text{where}\quad d_j = \langle v_j | \psi \rangle.
$$&lt;/p&gt;
&lt;p&gt;The step goes as follows: first, express the coefficient $d_j$ as above. Then, insert an identity, and using the resolution of the identity matrix &lt;em&gt;in&lt;/em&gt; ${ |u_i \rangle }$ basis, we find an expression that relates the coefficient $d_j$ and $c_i$. Mathematically,&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
d_j &amp;amp;= \langle v_j | \psi \rangle = \langle v_j | \mathbb{I} | \psi \rangle = \langle v_j | \left( \sum_i |u_i \rangle \langle u_i | \right) | \psi \rangle \\&lt;br&gt;
&amp;amp;= \sum_i \langle v_j | u_i \rangle \langle u_i | \psi \rangle = \sum_i S_{ji} c_i.
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Thus, to compute $d_j$ given $c_i$, we simply need to compute the quantity $S_{ji} = \langle v_j | u_i \rangle$, which is called an &amp;ldquo;overlap.&amp;rdquo; Using the matrix formulation we studied in the previous chapter, we can also express this relationship as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix}
d_1\\&lt;br&gt;
d_2\\&lt;br&gt;
\vdots
\end{bmatrix} =
\begin{bmatrix}
S_{11} &amp;amp; S_{12} &amp;amp; \cdots \\&lt;br&gt;
S_{21} &amp;amp; S_{22} &amp;amp; \cdots  \\&lt;br&gt;
\vdots &amp;amp; \vdots &amp;amp;  \ddots  \\&lt;br&gt;
\end{bmatrix}
\cdot
\begin{bmatrix}
c_1\\&lt;br&gt;
c_2\\&lt;br&gt;
\vdots
\end{bmatrix}.
$$&lt;/p&gt;
&lt;p&gt;We can also compute $c_i$ given $d_j$ in a similar fashion. If you follow the steps similar to the mathematical derivation above, it turns out that:&lt;/p&gt;
&lt;p&gt;$$
c_i = \sum_j \langle u_i | v_j \rangle d_j \quad\text{where}\quad \langle u_i | v_j \rangle = \langle v_j | u_i \rangle^* = S_{ji}^*.
$$&lt;/p&gt;
&lt;p&gt;To close this chapter, let&amp;rsquo;s look at how we perform a change of basis with an operator $\hat{A}$. We write the elements of operator $\hat{A}$ in ${ |u_i\rangle }$  basis and ${ |v_j\rangle }$ basis as $A_{ik}^u = \langle u_i | \hat{A} | u_k \rangle$ and $A_{j\ell}^v = \langle v_j | \hat{A} | v_\ell \rangle$, respectively. Then, we can compute $A_{j\ell}^v$ in terms of $A_{ik}^u$ as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
A_{j\ell}^v &amp;amp;= \langle v_j | \hat{A} | v_\ell \rangle = \langle v_j | \mathbb{I}\hat{A}\mathbb{I} | v_\ell \rangle \\&lt;br&gt;
&amp;amp;= \langle v_j | \left( \sum_i |u_i\rangle\langle u_i| \right) \hat{A} \left( \sum_k |u_k\rangle \langle u_k| \right) | v_\ell \rangle \\&lt;br&gt;
&amp;amp;=\sum_{i,~k} \langle v_j | u_i \rangle \langle u_i | \hat{A} | u_k \rangle \langle u_k | v_\ell \rangle \\&lt;br&gt;
&amp;amp;= \sum_{i,~k} S_{ji} A_{ik}^u S_{\ell k}^*.
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;Again, we can also go in the opposite direction. It turns out that to express $A_{ik}^u$ in terms of $A_{j\ell}^v$ is:&lt;/p&gt;
&lt;p&gt;$$
A_{ik}^u = \sum_{j,~\ell}S_{ji}^*A_{j\ell}^v S_{\ell k}.
$$&lt;/p&gt;
&lt;h2 id=&#34;6-eigenvalues-and-eigenstates-in-quantum-mechanics&#34;&gt;6. Eigenvalues and eigenstates in quantum mechanics&lt;/h2&gt;
&lt;p&gt;As we saw in Chapter 2 of the &lt;a href=&#34;https://jlylekim.github.io/post/quantum-mechanics-1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous post&lt;/a&gt;, operators are mathematical objects that allow us to describe physical properties. Eigenvalues and eigenstates are particularly important in quantum mechanics, because when we measure the physical properties, the only possible outcome is one of the eigenvalues of the associated operator; also, the state of system, after the measurement, is in the corresponding eigenstate. We start with the third postulate of quantum mechanics that summarizes the above:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postulate III:&lt;/strong&gt; The result of a measurement of a physical quantity is one of the eigenvalues of the associated observable.&lt;/p&gt;
&lt;p&gt;Mathematically, we can write down the eigenvalue equation as follows:&lt;/p&gt;
&lt;p&gt;$$
\hat{A} |\psi\rangle = \lambda |\psi \rangle,
$$&lt;/p&gt;
&lt;p&gt;where $\hat{A}$ is an operator, $|\psi\rangle$ is a &amp;ldquo;special&amp;rdquo; ket called eigenstate (i.e. eigenvector) of $\hat{A}$, and $\lambda$ is the eigenvalue of $\hat{A}$.  As can be seen, the operator $\hat{A}$ takes the ket $|\psi\rangle$ as an input, and outputs the same ket $|\psi\rangle$, only scaled with $\lambda$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basics of Quantum Mechanics 1</title>
      <link>https://jlylekim.github.io/blog/quantum-mechanics-1/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://jlylekim.github.io/blog/quantum-mechanics-1/</guid>
      <description>&lt;!--# Basics quantum mechanics: part 1--&gt;
&lt;p&gt;In this series of blog posts, I want to introduce some basics of quantum mechanics, which can be helpful to start learning about quantum computing. I myself do not have any physics background, and found &lt;a href=&#34;https://www.youtube.com/playlist?list=PL8W2boV7eVfmMcKF-ljTvAJQ2z-vILSxb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this series of videos&lt;/a&gt; extremely helpful. This post is mainly based on this series of lectures, and I hope it is helpful to anyone who wants to start learning quantum computing.&lt;/p&gt;
&lt;h2 id=&#34;1-dirac-notation-in-state-space&#34;&gt;1. Dirac notation in state space&lt;/h2&gt;
&lt;p&gt;State space is the name we give to the vector space in which the quantum system lives. Just like Euclidean space, which is used to describe the &amp;ldquo;world&amp;rdquo; in classical mechanics, state space is another vector space that shares many similarities with Euclidean space. For instance, just like Euclidean space, state space also is equipped with an inner product, thus making it a Hilbert space.&lt;/p&gt;
&lt;p&gt;Even though we use a lot of linear algebra in quantum mechanics, we use quite different notation, called &amp;ldquo;Dirac notation,&amp;rdquo; invented by one of the founders quantum mechanics, Paul Dirac. We start with the first postulate of quantum mechanics:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postulate I:&lt;/strong&gt; The state of a physical system is characterized by a state vector that belongs to a complex vector space $\mathcal{V}$, called the state space of the system.&lt;/p&gt;
&lt;p&gt;It turns out that the vector space properties that Euclidean space has mostly translates to state space, with a few tweaks. Let&amp;rsquo;s recap the properties of (3-dimensional) Euclidean space first.&lt;/p&gt;
&lt;p&gt;Euclidean space (in 3-dimension for illustration) has the following properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An element $r$ is called a (3-dimensional) &amp;ldquo;vector&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Vector addition: $r_1 + r_2 = r_3 \in \mathbb{R}^3$&lt;/li&gt;
&lt;li&gt;Commutativity of vector addition: $r_1 + r_2 = r_2 + r_1$&lt;/li&gt;
&lt;li&gt;Associativity of vector addition: $(r_1 + r_2) + r_3 = r_1 + (r_2 + r_3)$&lt;/li&gt;
&lt;li&gt;Identity for vector addition: $0 + r = r$&lt;/li&gt;
&lt;li&gt;Inverse of vector addition: $r + (-r) = 0$&lt;/li&gt;
&lt;li&gt;Scalar multiplication: $a \cdot r \in \mathbb{R}^3$&lt;/li&gt;
&lt;li&gt;Associativity of scalar multiplication: $a(br) = (ab)r$&lt;/li&gt;
&lt;li&gt;Distributivity of scalar multiplication: $(a + b )r = ar + br$, and $a(r_1 + r_2) = ar_1 + ar_2$&lt;/li&gt;
&lt;li&gt;Identity for vector multiplication: $1\cdot r = r$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above properties more or less translate directly to state space.&lt;/p&gt;
&lt;p&gt;State space $\mathcal{V}$ has the following properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An element $| \psi \rangle$ is called a &amp;ldquo;ket&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Vector addition: $|\psi_1 \rangle + |\psi_2\rangle = |\psi_3 \rangle \in \mathcal{V}$&lt;/li&gt;
&lt;li&gt;Commutativity of vector addition: $|\psi_1 \rangle + |\psi_2\rangle = |\psi_2 \rangle + |\psi_1 \rangle$&lt;/li&gt;
&lt;li&gt;Associativity of vector addition: $(|\psi_1 \rangle + |\psi_2\rangle) + |\psi_3\rangle = |\psi_1 \rangle + (|\psi_2\rangle +|\psi_3\rangle)$&lt;/li&gt;
&lt;li&gt;Identity for vector addition: $0 + |\psi\rangle = |\psi \rangle$&lt;/li&gt;
&lt;li&gt;Inverse of vector addition:$|\psi \rangle + (- |\psi \rangle) = 0$&lt;/li&gt;
&lt;li&gt;Sacalar multiplication: $a | \psi \rangle \in \mathcal{V}$&lt;/li&gt;
&lt;li&gt;Associativity of scalar multiplication: $a( b | \psi \rangle ) = (ab) | \psi \rangle$&lt;/li&gt;
&lt;li&gt;Distributivity of scalar multiplication: $(a+b) | \psi \rangle = a| \psi \rangle + b | \psi \rangle$, and $a ( | \psi_1 \rangle + | \psi_2 \rangle ) = a| \psi_1 \rangle + b| \psi_2 \rangle$&lt;/li&gt;
&lt;li&gt;Identity for vector multiplication: $1 | \psi \rangle = | \psi \rangle$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, we move to some differences. Both Euclidean space and state space are subsets of Hilbert space, and thus are equipped with scalar (inner) product.&lt;/p&gt;
&lt;p&gt;Scalar product in Euclidean space:&lt;/p&gt;
&lt;p&gt;$SP(r_1, r_2) = r_1 \bullet r_2 = c, \quad c \in \mathbb{R}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conjugation: $r_1 \bullet r_2 = r_2 \bullet r_1$&lt;/li&gt;
&lt;li&gt;Linearity: $r_1 \bullet a (r_2) = a(r_1) \bullet r_2 =  a(r_1 \bullet r_2)$  and $r_1 \bullet (r_2 + r_3) = r_1 \bullet r_2 + r_1 + r_3$&lt;/li&gt;
&lt;li&gt;Positivity: $r_1 \bullet r_1 \geq 0$, and $r_1 \bullet r_2 = 0$ if and only if $r_1 = 0$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Scalar product in state space:&lt;/p&gt;
&lt;p&gt;$SP(|\psi_1,~|\psi_2\rangle) = c, \quad c \in \mathbb{C}$&lt;/p&gt;
&lt;p&gt;Notice that the scalar $c$ is now a complex number, which is one of the crucial differences of state space and Euclidean space. Now we look at the properties of scalar product in state space:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conjugation: $SP(|\psi \rangle,~|\phi \rangle) = [SP(|\phi \rangle,~|\psi \rangle)]^*$&lt;/li&gt;
&lt;li&gt;Linearity in second argument: $SP(|\psi \rangle,~a |\phi \rangle) = a SP(|\psi \rangle,~|\phi \rangle)$ and $SP(|\psi \rangle,~|\phi \rangle + |\chi\rangle) = SP(|\psi \rangle,~|\phi \rangle) + SP(|\psi \rangle,~|\chi \rangle)$&lt;/li&gt;
&lt;li&gt;Anti-linearity in first argument: $SP(a|\psi \rangle,~ |\phi \rangle) = [SP(|\psi \rangle,~a|\psi \rangle)]^* = a^*[SP(|\phi \rangle, |\psi\rangle)
]^* = a^* SP(|\psi \rangle, |\phi \rangle)$ where $a^*$ is a complex conjugate.&lt;/li&gt;
&lt;li&gt;Positivity: $SP( |\psi \rangle, |\psi \rangle ) \geq 0$, and $SP( |\psi \rangle, |\psi \rangle ) = 0$ iff $|\psi \rangle = 0$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So the main difference comes from the fact that state space lives in complex vector space, rather than real vector space. Through the scalar product, we can define some basic notations for quantum mechanics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$SP(|\psi\rangle, |\phi\rangle)  \implies \langle \psi |\phi \rangle$ is called &amp;ldquo;braket.&amp;rdquo; As one can guess, $\langle \psi |$ is called &amp;ldquo;bra,&amp;rdquo; and it corresponds to a row vector.&lt;/li&gt;
&lt;li&gt;As one can guess, $\langle \psi |$ is called &amp;ldquo;bra,&amp;rdquo; and it corresponds to a row vector. (And of course $|\phi \rangle$ corresponds to a column vector.)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Ket&amp;rdquo; $|\psi \rangle \in \mathcal{V}$ maps to &amp;ldquo;bra&amp;rdquo; $\langle \psi | \in \mathcal{V}^*$ in dual space&lt;/li&gt;
&lt;li&gt;Scalar product is anti-linear in the first argument: $a|\psi\rangle \longleftrightarrow a^* \langle \psi |$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With this basic notation equipped, let&amp;rsquo;s study a concept called &amp;ldquo;operators&amp;rdquo; in the next chapter.&lt;/p&gt;
&lt;h2 id=&#34;2-operators-in-quantum-mechanics&#34;&gt;2. Operators in quantum mechanics&lt;/h2&gt;
&lt;p&gt;Operators are mathematical objects that allow us to describe physical properties, such as position, momentum, and energy. Let&amp;rsquo;s start by the second postulate of quantum mechanics:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Postulate II:&lt;/strong&gt; A physical quantity $\mathcal{A}$ is described by an operator $\hat{A}$ acting on the state space space $\mathcal{V}$, and this operator is an observable.&lt;/p&gt;
&lt;p&gt;In other words, an operator acts on elements of state space $\mathcal{V}$, which are kets, and these kets are modified by the operator $\hat{A}$ in some manner. This can be written is $\hat{A} |\psi \rangle = |\psi&#39; \rangle$, meaning that the operator $\hat{A}$ acts on the ket $| \psi \rangle$, which is modified to another ket $|\psi&#39; \rangle$. It&amp;rsquo;s important to remember that the operators in quantum mechanics can act on the superposition of different states:&lt;/p&gt;
&lt;p&gt;$$\hat{A} (a_1 |\psi_1 \rangle + a_2 |\psi_2 \rangle) = a_1 \hat{A} |\psi_1 \rangle + a_2 \hat{A} | \psi_2 \rangle.$$&lt;/p&gt;
&lt;p&gt;As can be guessed from the above expression, these operators are called &amp;ldquo;linear operators.&amp;rdquo; Fortunately, in quantum mechanics, we can always work with linear operators, which makes the study of quantum mechanics a lot easier. Similarly to the properties of addition and multiplication of kets we studied earlier, (linear) operators have basic properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Associativity of addition: $\hat{A} + (\hat{B} + \hat{C}) = (\hat{A} + \hat{B}) + \hat{C}$&lt;/li&gt;
&lt;li&gt;Commutativity of addition: $\hat{A} + \hat{B} = \hat{B} + \hat{A}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before stating the properties of multiplication of operators, let&amp;rsquo;s start with its definition:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multiplication of operators: $(\hat{A}\hat{B}) |\psi\rangle = \hat{A} ( \hat{B} |\psi \rangle )$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Above can also be thought of as $\hat{A}$ acting on the new state, $\hat{B} |\psi \rangle = |\psi&#39; \rangle$, i.e. $\hat{A} |\psi&#39; \rangle$. Now we state the properties of multiplication of operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Associativity of multiplication: $\hat{A} (\hat{B}\hat{C}) = (\hat{A} \hat{B}) \hat{C}$&lt;/li&gt;
&lt;li&gt;Non-commutativity of multiplication: $\hat{A} \hat{B} \neq \hat{B} \hat{A}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The non-commutativity of multiplication is one of the most important properties of operators in quantum mechanics. Due to this aspect, we also define commutators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Commutator: $[\hat{A}, \hat{B}] = \hat{A}\hat{B} - \hat{B} \hat{A}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The non-commutativity of multiplication of operators, and consequently the notion of  commutators play a fundamental role in quantum mechanics. Specifically, two operators that do not commute are associated with properties that cannot be measured simultaneously in a quantum system, such as position and momentum operators.&lt;/p&gt;
&lt;p&gt;Now, we introduce the notion of the adjoint operator. Adjoint operator can be thought of as the dual of the operator introduced above, just like a ket corresponds to a bra in the dual space. We can write this as follows:&lt;/p&gt;
&lt;p&gt;$$|\psi&#39;\rangle =\hat{A}|\psi \rangle \longleftrightarrow \langle \psi&#39; | = \langle \psi|\hat{A}^\dagger.$$&lt;/p&gt;
&lt;p&gt;Adjoint operator is also linear, just like the operator introduced previously. With this notion, we can introduce some particularly important operators in quantum mechanics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hermitian operator: $\hat{A} = \hat{A}^\dagger$&lt;/li&gt;
&lt;li&gt;Unitary operator: $\hat{A}^{-1} = \hat{A}^\dagger$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another important way to write an operator is through &amp;ldquo;outer product.&amp;rdquo; It turns out that outer product is also an operator, which can be seen below:&lt;/p&gt;
&lt;p&gt;$$(|\phi \rangle \langle \psi | ) |\chi \rangle = | \phi \rangle ( \langle \psi | \chi \rangle ) = a|\phi \rangle,$$&lt;/p&gt;
&lt;p&gt;where we denoted the scalar (inner) product $\langle \psi | \chi \rangle$ as $a \in \mathbb{C}$.&lt;/p&gt;
&lt;p&gt;We close this chapter with some basic mathematical properties of operators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\langle \psi | \hat{A}^\dagger | \rho \rangle = \langle \rho |\hat{A}|\psi\rangle^*$&lt;/li&gt;
&lt;li&gt;$(\hat{A}^\dagger)^\dagger = \hat{A}$&lt;/li&gt;
&lt;li&gt;$(a \hat{A})^\dagger = a^* \hat{A}^\dagger$&lt;/li&gt;
&lt;li&gt;$(\hat{A} + \hat{B})^\dagger = \hat{A}^\dagger + \hat{B}^\dagger$&lt;/li&gt;
&lt;li&gt;$(\hat{A}\hat{B})^\dagger = \hat{B}^\dagger \hat{A}^\dagger$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-representations-in-quantum-mechanics&#34;&gt;3. Representations in quantum mechanics&lt;/h2&gt;
&lt;p&gt;Just like choosing convenient basis in Euclidean space leads to simpler notations, in quantum mechanics, if we choose convenient basis, it can simplify mathematical representations as well. We represent state space with an orthonormal basis. Orthonormal basis are mathematically defined as a set $\{ |u_i\rangle \}$ such that $\langle u_i | u_j \rangle = \delta_{ij}$, where $\delta_{ij} = 1$ if $i = j$, and $0$ otherwise (this is known as the &amp;ldquo;kronecker delta&amp;rdquo; function). Also, every ket in the state space, $|\psi \rangle \in \mathcal{V}$, can be respresented as a unique linear combination of the set $\{ |u_i\rangle \}$, i.e. $|\psi \rangle = \sum_i c_i |u_i \rangle$.&lt;/p&gt;
&lt;p&gt;Since we&amp;rsquo;re working with orthonormal basis, it is quite easy to find a specific coefficient as follows:&lt;/p&gt;
&lt;p&gt;$$\langle u_j | \psi \rangle = \langle u_j | \left( \sum_i c_i |u_i \rangle \right) = \sum_i c_i \langle u_j | u_i \rangle = \sum_i c_i \delta_{ij} = c_j.$$&lt;/p&gt;
&lt;p&gt;In words, we can say that $\{ c_i \}$ are a representation of a ket $|\psi \rangle$ in the $\{ |u_i\rangle \}$ basis. An important concept of representation is &amp;ldquo;closure relation&amp;rdquo;:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
|\psi \rangle &amp;amp;= \sum_i \langle u_i | \psi \rangle |u_i \rangle  = \left( \sum_i |u_i \rangle \langle u_i \right) | \psi \rangle \\&lt;br&gt;
&amp;amp;= \sum_i c_i | u_i\rangle \quad \text{where}\quad c_i = \langle u_i | \psi \rangle.
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Recall from Chapter 2 that an operator can be written as an outer product. In that sense, from the above, we can see that $\sum_i |u_i \rangle \langle u_i |$ is an operator (notice that I emphasized this with parentheses) that, given a state $|\psi\rangle$, returns the same state $|\psi \rangle$. Thus, we can also write $\sum_i |u_i \rangle \langle u_i | = \mathbb{I}$, where $\mathbb{I}$ is an identity matrix. This result is sometimes also called the &amp;ldquo;resultion of the identity (in the $\{|u_i\rangle \}$ basis).&amp;rdquo; Similar result holds for a bra $\langle \psi | \in \mathcal{V}^*$ :&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\langle \psi | = \langle \psi | \mathbb{I} = \langle \psi | \left(  \sum_i |u_i \rangle \langle u_i | \right) &amp;amp;= \sum_i \langle \psi | u_i \rangle \langle u_i |  \\&lt;br&gt;
&amp;amp;= \sum_i c_i^* \langle u_i |  \quad \text{where} \quad c_i^* = \langle u_i | \psi \rangle^*  = \langle \psi | u_i \rangle.
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s look at how we represent operators. Recall the definition of an operator $\hat{A} |\psi\rangle = |\psi&#39; \rangle$. Using the same $\{ |u_i \rangle \}$ basis as before, we can write down both kets as below:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
|\psi\rangle &amp;amp;= \sum_i c_i | u_i \rangle \quad\text{for}\quad c_i = \langle u_i | \psi \rangle \\&lt;br&gt;
|\psi&#39;\rangle &amp;amp;= \sum_i c_i&#39; | u_i \rangle \quad\text{for}\quad c_i&#39; = \langle u_i | \psi&#39; \rangle.
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Notice that we can write $c_i&#39;$ in an alternative way as follows:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
c_i&#39; &amp;amp;= \langle u_i | \psi&#39; \rangle = \langle u_i | \hat{A} | \psi \rangle = \langle u_i | \hat{A}\mathbb{I} | \psi \rangle
\quad\text{(recall closure relation)}
\\ &amp;amp;= \langle u_i | \hat{A} \left( \sum_j |u_j \rangle \langle u_j | \right) |\psi\rangle = \sum_j \langle u_i |\hat{A} |u_j \rangle \langle u_j | \psi \rangle.
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Using this alternative form of $c_i&#39;$, we can write down the ket $|\psi&#39;\rangle$ in a different form:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
|\psi&#39;\rangle &amp;amp;= \sum_i \left( \sum_j \langle u_i|\hat{A}|u_j \rangle \langle u_j|\psi\rangle \right) |u_i\rangle \\&lt;br&gt;
&amp;amp;= \left( \sum_{ij} |u_i \rangle \langle u_i | \hat{A}| u_j \rangle \langle u_j| \right) |\psi\rangle \\&lt;br&gt;
&amp;amp;= \hat{A} |\psi\rangle.
\end{aligned}$$&lt;/p&gt;
&lt;p&gt;Therefore, we see that we can write the operator $\hat{A}$ as&lt;/p&gt;
&lt;p&gt;$$\hat{A} = \left( \sum_{ij} |u_i \rangle \langle u_i | \hat{A}| u_j \rangle \langle u_j| \right) = \sum_{ij} A_{ij} |u_i\rangle \langle u_j|,$$&lt;/p&gt;
&lt;p&gt;where $A_{ij} = \langle u_i | \hat{A} | u_j \rangle \in \mathbb{C}$. Therefore, we arrive at a scalar value $A_{ij}$ that represents the operator $\hat{A}$ in the $\{ |u_i\rangle \}$ basis, just like how $c_i = \langle u_i | \psi \rangle$ represents the ket $|\psi \rangle$ in the same basis.&lt;/p&gt;
&lt;p&gt;With the above, we close this chapter, and thus part 1 of this blog post about basics of quantum mechanics. In the next part, we will study matrix formulation of quantum mechanics, how to change basis, and a particularly import basis called eigenbasis.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
